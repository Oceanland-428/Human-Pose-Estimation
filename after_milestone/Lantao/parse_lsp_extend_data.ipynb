{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.image as img\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from os.path import basename as b\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_image(original_image_path):\n",
    "    image = misc.imread(original_image_path)\n",
    "#     print(image.shape)\n",
    "    # scale the image to 227*227\n",
    "    scaled_image = misc.imresize(image, (227, 227), interp='bicubic')\n",
    "    return scaled_image, image.shape[0], image.shape[1] # first height and then width, don't mess up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_label(label, original_height, original_width):\n",
    "    label[0, :] *= (227 / float(original_width))  # label x is corresponding to width\n",
    "    label[1,:] *= (227 / float(original_height))  # label y is corresponding to height, don't mess up!\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(image_paths,labels,dataset):\n",
    "    num_examples = image_paths.shape[0]\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    print('Start to process '+ dataset + ' dataset')\n",
    "    for index in range(num_examples):\n",
    "        image, or_height, or_width = prepare_image(image_paths[index])\n",
    "        image_list.append(image)\n",
    "        label = scale_label(labels[index], or_height, or_width)\n",
    "        label = label[:2,:]\n",
    "        label_list.append(label)\n",
    "    print('Done processing the ' + dataset + ' dataset')\n",
    "    return np.array(image_list), np.array(label_list)   # change to np array for future operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLSPExtendDataset(train_set_ratio=0.8,validation_set_ratio = 0.1):\n",
    "    print('Resizing and packing images and labels to lists.\\n')\n",
    "    np.random.seed(1701)  # to fix test set\n",
    "    # load the dataset. Make sure you put the joints.mat in the same folder as this .ipynb or .py program\n",
    "    # otherwise you can change the path here\n",
    "    joints = loadmat('joints.mat')\n",
    "    # transpose the shape to N*C*number of features, in this case it is 2000*3*14\n",
    "    joints = joints['joints'].transpose(2, 1, 0)\n",
    "    \n",
    "    # I saw some code such as this one: https://github.com/samitok/deeppose/blob/master/Codes/Original/GetLSPData.py only extracts two joints\n",
    "    # which is Right ankle and Right knee\n",
    "    # this one as well: https://github.com/mitmul/deeppose/blob/master/datasets/lsp_dataset.py\n",
    "    # invisible_joints = joints[:, :, 2] < 0.5\n",
    "    # joints[invisible_joints] = 0\n",
    "    # joints = joints[..., :2]\n",
    "    \n",
    "    # get the list of images names. Make sure you put the images directory in the same folder as this .ipynb or .py program\n",
    "    # otherwise you can change the path here\n",
    "    image_list = np.asarray(sorted(glob.glob('./images/*.jpg')))\n",
    "    \n",
    "    # get image indexes\n",
    "    image_indexes = list(range(0, len(image_list)))\n",
    "    \n",
    "    # random shuffle the data\n",
    "    # shuffle the index and use the indexes to select images. So it is equivalent to shuffle images\n",
    "    np.random.shuffle(image_indexes)\n",
    "   \n",
    "    # get the training, val and test set indexes\n",
    "    train_validation_split = int(len(image_list)*train_set_ratio)\n",
    "    validation_test_split = int(len(image_list)*(train_set_ratio+validation_set_ratio))\n",
    "    train_indexes = np.asarray(image_indexes[:train_validation_split])\n",
    "    validation_indexes = np.asarray(image_indexes[train_validation_split:validation_test_split])\n",
    "    test_indexes = np.asarray(image_indexes[validation_test_split:])\n",
    "\n",
    "    # generate label\n",
    "    train_list,train_label = generate_dataset(image_list[train_indexes],joints[train_indexes],'training')\n",
    "    val_list,val_label = generate_dataset(image_list[validation_indexes],joints[validation_indexes],'validation')\n",
    "    test_list,test_label = generate_dataset(image_list[test_indexes],joints[test_indexes],'test')\n",
    "    \n",
    "    return train_list,train_label,val_list,val_label,test_list,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing and packing images and labels to lists.\n",
      "\n",
      "Start to process training dataset\n",
      "Done processing the training dataset\n",
      "Start to process validation dataset\n",
      "Done processing the validation dataset\n",
      "Start to process test dataset\n",
      "Done processing the test dataset\n"
     ]
    }
   ],
   "source": [
    "train_list,train_label,val_list,val_label,test_list,test_label = getLSPExtendDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
