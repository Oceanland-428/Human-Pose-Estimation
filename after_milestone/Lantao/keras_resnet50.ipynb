{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from parse_lsp_data import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import image\n",
    "from keras import applications\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "# from keras.utils import np_utils\n",
    "# from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger\n",
    "# from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout,Reshape\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten,Activation, Average\n",
    "from image_noise_generation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data set\n",
    "train_list, train_label, val_list, val_label, test_list, test_label = getLSPDataset(0.9, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some information\n",
    "train_X = train_list\t# (N, 227, 227, 3)\n",
    "train_Y = train_label\t# (N, 2, 14)\n",
    "# train_X,train_Y = data_augmentation(train_X,train_Y)\n",
    "print(\"train X: \", train_X.shape, \"val X: \", val_list.shape, \"test X: \", test_list.shape)\n",
    "print(\"train Y: \", train_Y.shape, \"val Y: \", val_label.shape, \"test Y: \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_input = Input(shape=(227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keras model\n",
    "def build_model():\n",
    "    base_model = applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(227,227, 3))\n",
    "    last = base_model.output\n",
    "    x = Flatten()(last)\n",
    "#     x = Dropout(0.7)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(28, activation='relu')(x)\n",
    "    preds = Reshape((2,14))(x)\n",
    "    model = Model(base_model.input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function (L2 distance)\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true)))/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "def accuracy(y_true, y_pred):\n",
    "    \n",
    "    diff = K.square(y_true - y_pred)\n",
    "#     loss = K.sum(diff)\n",
    "    dist = K.sqrt(K.sum(diff, axis = 1))\t# (N, 2, 14) -> (N, 14)\n",
    "#     accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 64/14\n",
    "    torsor_xy = y_true[:,:,9] - y_true[:,:,2] # (N,2)\n",
    "    torsor_dist = K.sqrt(K.sum(K.square(torsor_xy),axis=1,keepdims=True)) #(N,1)\n",
    "    torsor_frac = thresh*torsor_dist\n",
    "    \n",
    "    accuracy = K.sum(K.cast(K.greater(torsor_frac,dist),dtype='float32'))/64/14\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('resnet50_t05_lr00005_dp09_v2.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history = model.fit(train_X, train_Y, epochs=100,batch_size=64, validation_data = (val_list,val_label),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "with tf.device('/device:GPU:0'):\n",
    "    loss,acc = model.evaluate(test_list, test_label,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    pred = model.predict(test_list)with tf.device('/device:GPU:0'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[0])\n",
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = K.sqrt(K.sum(K.square(pred[0] - test_label[0]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.array(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.reduce_sum(tf.to_int32(tf.greater(threshold, dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet50_t05_lr00005_dp09_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "def load_trained_model(weights_path):\n",
    "    model = build_model()\n",
    "    model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model('resnet50_t05_lr00005_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred2 = train_model.predict(train_list)\n",
    "pred_train = model.predict(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model.predict(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage:\n",
    "# drawLines(val_list[5].copy(),val_label[5].copy(),pred3[5].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from drawLines_v2 import drawLines\n",
    "# usage:\n",
    "index = 5\n",
    "drawLines(test_list[index].copy(),test_label[index].copy(),pred_test[index].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drawLines_v2 import drawLines\n",
    "index = 71\n",
    "drawLines(val_list[index].copy(),val_label[index].copy(),pred_val[index].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage:\n",
    "index2 = 5\n",
    "drawLines(train_list[index2].copy(),train_label[index2].copy(),pred_train[index2].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ankle validation acc\n",
    "thresh = 0.0\n",
    "\n",
    "diff = np.square(val_label - pred_val)\n",
    "#     loss = K.sum(diff)\n",
    "dist = np.sqrt(np.sum(diff, axis = 1))[:,[7,10]]\t# (N, 2, 14) -> (N, 14)\n",
    "#     accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 64/14\n",
    "torsor_xy = val_label[:,:,9] - val_label[:,:,2] # (N,2)\n",
    "torsor_dist = np.sqrt(np.sum(np.square(torsor_xy),axis=1,keepdims=True)) #(N,1)\n",
    "torsor_frac = thresh*torsor_dist\n",
    "\n",
    "test_accuracy = np.sum(np.greater(torsor_frac,dist))/200/2\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute knee validation acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute wrists validation acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute elbows validation acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# def load_trained_model(weights_path):\n",
    "#     model = build_model()\n",
    "#     model.load_weights(weights_path)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_trained_model('resnet50_t05_lr00005.h5')\n",
    "# model.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cascade\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     pred = model.predict(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "#     pred_val = model.predict(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crop_image_keras_v2 import images_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_image_matrix,actual_reshape_size_matrix = images_crop(train_list.copy(),pred_train.copy(),train_label.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_image_matrix_val,actual_reshape_size_matrix_val = images_crop(val_list.copy(),pred_val.copy(),val_label.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "#     crop_image_matrix = crop_image_matrix.transpose(0,2,3,4,1).reshape(1600,227,227,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "#     crop_image_matrix_val = crop_image_matrix_val.transpose(0,2,3,4,1).reshape(200,227,227,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put reshape information and previous stage's prediction into y_true, this is an implementation trick\n",
    "# in this case we have reshape information and previous prediction along each batch\n",
    "stage2_Y = np.concatenate((train_Y,actual_reshape_size_matrix,pred_train),axis=1)\n",
    "stage2_Y_val = np.concatenate((val_label,actual_reshape_size_matrix_val,pred_val),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keras model\n",
    "# def stage2():\n",
    "#     base_model = applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(227,227, 3,14))\n",
    "#     last = base_model.output\n",
    "#     x = Flatten()(last)\n",
    "# #     x = Dropout(0.7)(x)\n",
    "#     x = Dense(4096, activation='relu')(x)\n",
    "#     x = Dropout(0.7)(x)\n",
    "#     x = Dense(4096, activation='relu')(x)\n",
    "#     x = Dropout(0.7)(x)\n",
    "#     x = Dense(28, activation='relu')(x)\n",
    "#     preds = Reshape((2,14))(x)\n",
    "#     model = Model(base_model.input, preds)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage2_model = stage2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keras model\n",
    "def build_cascade_model():\n",
    "    base_model = applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(227,227, 3))\n",
    "    last = base_model.output\n",
    "    x = Flatten()(last)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(84, activation='relu')(x)\n",
    "    preds = Reshape((6,14))(x) # an implementation trick here. Only 2*14 is used for displacement prediction. The result is to match the shape of y_true as stated above\n",
    "    model = Model(base_model.input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function (L2 distance)\n",
    "def euclidean_distance_loss_stageS(y_true, y_pred):\n",
    "    \n",
    "    y_true_labels = y_true[:,:2,:]  # (N,2,14)\n",
    "    reshape_matrix = y_true[:,2:4,:] # (N,2,14)\n",
    "    y_pred_prev = y_true[:,4:,:] # (N,2,14)\n",
    "    y_pred_resize = y_pred_prev + y_pred[:,:2,:]*reshape_matrix/227\n",
    "    return K.sqrt(K.sum(K.square(y_pred_resize - y_true_labels)))/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true_labels = y_true[:,:2,:]  # (N,2,14)\n",
    "    reshape_matrix = y_true[:,2:4,:] # (N,2,14)\n",
    "    y_pred_prev = y_true[:,4:,:] # (N,2,14)\n",
    "    \n",
    "    y_pred_resize = y_pred_prev + y_pred[:,:2,:]*reshape_matrix/227\n",
    "    \n",
    "    diff = K.square(y_true_labels - y_pred_resize)\n",
    "#     loss = K.sum(diff)\n",
    "    dist = K.sqrt(K.sum(diff, axis = 1))\t# (N, 2, 14) -> (N, 14)\n",
    "#     accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 64/14\n",
    "    torsor_xy = y_true_labels[:,:,9] - y_true_labels[:,:,2] # (N,2)\n",
    "    torsor_dist = K.sqrt(K.sum(K.square(torsor_xy),axis=1,keepdims=True)) #(N,1)\n",
    "    torsor_frac = thresh*torsor_dist\n",
    "    \n",
    "    accuracy = K.sum(K.cast(K.greater(torsor_frac,dist),dtype='float32'))/64/14\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_matrix = np.zeros((1600,2,14))\n",
    "val_pred_matrix = np.zeros((200,2,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first joint\n",
    "temp_images0 = crop_image_matrix[:,0]\n",
    "temp_images_val = crop_image_matrix_val[:,0]\n",
    "cascade_model0 = build_cascade_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model0.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('stage2_0_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model0.fit(temp_images0, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model0.save('stage2_0_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train0 = cascade_model0.predict(temp_images0) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,0] = temp_pred2_train0[:,:2,0] + pred_train[:,:,0] # displacement + previous prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val0 = cascade_model0.predict(temp_images_val) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,0] = temp_pred2_val0[:,:2,0] + pred_val[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second joint\n",
    "index = 1\n",
    "temp_images1 = crop_image_matrix[:,index]\n",
    "temp_images_val1 = crop_image_matrix_val[:,index]\n",
    "cascade_model1 = build_cascade_model()\n",
    "cascade_model1.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_1_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model1.fit(temp_images1, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val1,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model1.save('stage2_1_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train1 = cascade_model1.predict(temp_images1) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train1[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val1 = cascade_model1.predict(temp_images_val1) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val1[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third joint\n",
    "index = 2\n",
    "temp_images2 = crop_image_matrix[:,index]\n",
    "temp_images_val2 = crop_image_matrix_val[:,index]\n",
    "cascade_model2 = build_cascade_model()\n",
    "cascade_model2.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_2_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model2.fit(temp_images2, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val2,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model2.save('stage2_2_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train2 = cascade_model2.predict(temp_images2) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train2[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val2 = cascade_model2.predict(temp_images_val2) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val2[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forth joint\n",
    "index = 3\n",
    "temp_images3 = crop_image_matrix[:,index]\n",
    "temp_images_val3 = crop_image_matrix_val[:,index]\n",
    "cascade_model3 = build_cascade_model()\n",
    "cascade_model3.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_3_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model3.fit(temp_images3, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val3,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model3.save('stage2_3_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train3 = cascade_model3.predict(temp_images3) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train3[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val3 = cascade_model3.predict(temp_images_val3) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val3[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth joint\n",
    "index = 4\n",
    "temp_images4 = crop_image_matrix[:,index]\n",
    "temp_images_val4 = crop_image_matrix_val[:,index]\n",
    "cascade_model4 = build_cascade_model()\n",
    "cascade_model4.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_4_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model4.fit(temp_images4, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val4,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model4.save('stage2_4_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train4 = cascade_model4.predict(temp_images4) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train4[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val4 = cascade_model4.predict(temp_images_val4) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val4[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sixth joint\n",
    "index = 5\n",
    "temp_images5 = crop_image_matrix[:,index]\n",
    "temp_images_val5 = crop_image_matrix_val[:,index]\n",
    "cascade_model5 = build_cascade_model()\n",
    "cascade_model5.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_5_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model5.fit(temp_images5, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val5,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model5.save('stage2_5_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train5 = cascade_model5.predict(temp_images5) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train5[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val5 = cascade_model5.predict(temp_images_val5) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val5[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seventh joint\n",
    "index = 6\n",
    "temp_images6 = crop_image_matrix[:,index]\n",
    "temp_images_val6 = crop_image_matrix_val[:,index]\n",
    "cascade_model6 = build_cascade_model()\n",
    "cascade_model6.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_6_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model6.fit(temp_images6, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val6,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model6.save('stage2_6_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train6 = cascade_model6.predict(temp_images6) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train6[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val6 = cascade_model6.predict(temp_images_val6) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val6[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eighth joint\n",
    "index = 7\n",
    "temp_images7 = crop_image_matrix[:,index]\n",
    "temp_images_val7 = crop_image_matrix_val[:,index]\n",
    "cascade_model7 = build_cascade_model()\n",
    "cascade_model7.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_7_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model7.fit(temp_images7, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val7,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model7.save('stage2_7_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train7 = cascade_model7.predict(temp_images7) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train7[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val7 = cascade_model7.predict(temp_images_val7) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val7[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ninth joint\n",
    "index = 8\n",
    "temp_images8 = crop_image_matrix[:,index]\n",
    "temp_images_val8 = crop_image_matrix_val[:,index]\n",
    "cascade_model8 = build_cascade_model()\n",
    "cascade_model8.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_8_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model8.fit(temp_images8, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val8,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model8.save('stage2_8_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train8 = cascade_model8.predict(temp_images8) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train8[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val8 = cascade_model8.predict(temp_images_val8) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val8[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenth joint\n",
    "index = 9\n",
    "temp_images9 = crop_image_matrix[:,index]\n",
    "temp_images_val9 = crop_image_matrix_val[:,index]\n",
    "cascade_model9 = build_cascade_model()\n",
    "cascade_model9.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_9_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model9.fit(temp_images9, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val9,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model9.save('stage2_9_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train9 = cascade_model9.predict(temp_images9) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train9[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val9 = cascade_model9.predict(temp_images_val9) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val9[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eleventh joint\n",
    "index = 10\n",
    "temp_images10 = crop_image_matrix[:,index]\n",
    "temp_images_val10 = crop_image_matrix_val[:,index]\n",
    "cascade_model10 = build_cascade_model()\n",
    "cascade_model10.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_10_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model10.fit(temp_images10, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val10,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model10.save('stage2_10_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train10 = cascade_model10.predict(temp_images10) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train10[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val10 = cascade_model10.predict(temp_images_val10) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val10[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12th joint\n",
    "index = 11\n",
    "temp_images11 = crop_image_matrix[:,index]\n",
    "temp_images_val11 = crop_image_matrix_val[:,index]\n",
    "cascade_model11 = build_cascade_model()\n",
    "cascade_model11.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_11_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model11.fit(temp_images11, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val11,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model11.save('stage2_11_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train11 = cascade_model11.predict(temp_images11) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train11[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val11 = cascade_model11.predict(temp_images_val11) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val11[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13th joint\n",
    "index = 12\n",
    "temp_images12 = crop_image_matrix[:,index]\n",
    "temp_images_val12 = crop_image_matrix_val[:,index]\n",
    "cascade_model12 = build_cascade_model()\n",
    "cascade_model12.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_12_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model12.fit(temp_images12, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val12,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model12.save('stage2_12_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train12 = cascade_model12.predict(temp_images12) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train12[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val12 = cascade_model12.predict(temp_images_val12) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val12[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14th joint\n",
    "index = 13\n",
    "temp_images13 = crop_image_matrix[:,index]\n",
    "temp_images_val13 = crop_image_matrix_val[:,index]\n",
    "cascade_model13 = build_cascade_model()\n",
    "cascade_model13.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss_stageS, metrics=[accuracy])\n",
    "csv_logger = CSVLogger('stage2_13_v4.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    cascade_model13.fit(temp_images13, stage2_Y, epochs=20,batch_size=64,validation_data = (temp_images_val13,stage2_Y_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model13.save('stage2_13_v4.h5')\n",
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train13 = cascade_model13.predict(temp_images13) # (N,6,14), but only (N,:2,14) are useful information. \n",
    "train_pred_matrix[:,:,index] = temp_pred2_train13[:,:2,index] + pred_train[:,:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val13 = cascade_model12.predict(temp_images_val13) # (N_prime,6,14)\n",
    "val_pred_matrix[:,:,index] = temp_pred2_val13[:,:2,index] + pred_val[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final train and val loss\n",
    "final_loss_train = np.sqrt(np.sum(np.square(train_Y - train_pred_matrix)))/1600\n",
    "print(final_loss_train)\n",
    "final_loss_val = np.sqrt(np.sum(np.square(val_label - val_pred_matrix)))/200\n",
    "print(final_loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final train acc\n",
    "thresh = 0.5\n",
    "   \n",
    "diff = np.square(train_Y - train_pred_matrix)\n",
    "#     loss = K.sum(diff)\n",
    "dist = np.sqrt(np.sum(diff, axis = 1))\t# (N, 2, 14) -> (N, 14)\n",
    "#     accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 64/14\n",
    "torsor_xy = train_Y[:,:,9] - train_Y[:,:,2] # (N,2)\n",
    "torsor_dist = np.sqrt(np.sum(np.square(torsor_xy),axis=1,keepdims=True)) #(N,1)\n",
    "torsor_frac = thresh*torsor_dist\n",
    "\n",
    "train_accuracy = np.sum(np.greater(torsor_frac,dist))/1600/14\n",
    "print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final val acc\n",
    "thresh = 0.5\n",
    "   \n",
    "diff = np.square(val_label - val_pred_matrix)\n",
    "#     loss = K.sum(diff)\n",
    "dist = np.sqrt(np.sum(diff, axis = 1))\t# (N, 2, 14) -> (N, 14)\n",
    "#     accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 64/14\n",
    "torsor_xy = val_label[:,:,9] - val_label[:,:,2] # (N,2)\n",
    "torsor_dist = np.sqrt(np.sum(np.square(torsor_xy),axis=1,keepdims=True)) #(N,1)\n",
    "torsor_frac = thresh*torsor_dist\n",
    "\n",
    "val_accuracy = np.sum(np.greater(torsor_frac,dist))/200/14\n",
    "print(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_image_matrix_test,actual_reshape_size_matrix_test = images_crop(test_list.copy(),pred_test.copy(),test_label.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images0 = crop_image_matrix_test[:,0]\n",
    "test_images1 = crop_image_matrix_test[:,1]\n",
    "test_images2 = crop_image_matrix_test[:,2]\n",
    "test_images3 = crop_image_matrix_test[:,3]\n",
    "test_images4 = crop_image_matrix_test[:,4]\n",
    "test_images5 = crop_image_matrix_test[:,5]\n",
    "test_images6 = crop_image_matrix_test[:,6]\n",
    "test_images7 = crop_image_matrix_test[:,7]\n",
    "test_images8 = crop_image_matrix_test[:,8]\n",
    "test_images9 = crop_image_matrix_test[:,9]\n",
    "test_images10 = crop_image_matrix_test[:,10]\n",
    "test_images11 = crop_image_matrix_test[:,11]\n",
    "test_images12 = crop_image_matrix_test[:,12]\n",
    "test_images13 = crop_image_matrix_test[:,13]\n",
    "\n",
    "test_pred_matrix = np.zeros((200,2,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_test0 = cascade_model0.predict(test_images0)\n",
    "    temp_pred2_test1 = cascade_model1.predict(test_images1)\n",
    "    temp_pred2_test2 = cascade_model2.predict(test_images2)\n",
    "    temp_pred2_test3 = cascade_model3.predict(test_images3)\n",
    "    temp_pred2_test4 = cascade_model4.predict(test_images4)\n",
    "    temp_pred2_test5 = cascade_model5.predict(test_images5)\n",
    "    temp_pred2_test6 = cascade_model6.predict(test_images6)\n",
    "    temp_pred2_test7 = cascade_model7.predict(test_images7)\n",
    "    temp_pred2_test8 = cascade_model8.predict(test_images8)\n",
    "    temp_pred2_test9 = cascade_model9.predict(test_images9)\n",
    "    temp_pred2_test10 = cascade_model10.predict(test_images10)\n",
    "    temp_pred2_test11 = cascade_model11.predict(test_images11)\n",
    "    temp_pred2_test12 = cascade_model12.predict(test_images12)\n",
    "    temp_pred2_test13 = cascade_model13.predict(test_images13)\n",
    "\n",
    "test_pred_matrix[:,:,0] = temp_pred2_test0[:,:2,0] + pred_test[:,:,0]\n",
    "test_pred_matrix[:,:,1] = temp_pred2_test1[:,:2,1] + pred_test[:,:,1]\n",
    "test_pred_matrix[:,:,2] = temp_pred2_test2[:,:2,2] + pred_test[:,:,2]\n",
    "test_pred_matrix[:,:,3] = temp_pred2_test3[:,:2,3] + pred_test[:,:,3]\n",
    "test_pred_matrix[:,:,4] = temp_pred2_test4[:,:2,4] + pred_test[:,:,4]\n",
    "test_pred_matrix[:,:,5] = temp_pred2_test5[:,:2,5] + pred_test[:,:,5]\n",
    "test_pred_matrix[:,:,6] = temp_pred2_test6[:,:2,6] + pred_test[:,:,6]\n",
    "test_pred_matrix[:,:,7] = temp_pred2_test7[:,:2,7] + pred_test[:,:,7]\n",
    "test_pred_matrix[:,:,8] = temp_pred2_test8[:,:2,8] + pred_test[:,:,8]\n",
    "test_pred_matrix[:,:,9] = temp_pred2_test9[:,:2,9] + pred_test[:,:,9]\n",
    "test_pred_matrix[:,:,10] = temp_pred2_test10[:,:2,10] + pred_test[:,:,10]\n",
    "test_pred_matrix[:,:,11] = temp_pred2_test11[:,:2,11] + pred_test[:,:,11]\n",
    "test_pred_matrix[:,:,12] = temp_pred2_test12[:,:2,12] + pred_test[:,:,12]\n",
    "test_pred_matrix[:,:,13] = temp_pred2_test13[:,:2,13] + pred_test[:,:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final test loss\n",
    "final_loss_test = np.sqrt(np.sum(np.square(test_label - test_pred_matrix)))/200\n",
    "print(final_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final test acc\n",
    "thresh = 0.5\n",
    "   \n",
    "diff = np.square(test_label - test_pred_matrix)\n",
    "#     loss = K.sum(diff)\n",
    "dist = np.sqrt(np.sum(diff, axis = 1))\t# (N, 2, 14) -> (N, 14)\n",
    "#     accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 64/14\n",
    "torsor_xy = test_label[:,:,9] - test_label[:,:,2] # (N,2)\n",
    "torsor_dist = np.sqrt(np.sum(np.square(torsor_xy),axis=1,keepdims=True)) #(N,1)\n",
    "torsor_frac = thresh*torsor_dist\n",
    "\n",
    "test_accuracy = np.sum(np.greater(torsor_frac,dist))/200/14\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(crop_image_matrix.shape)\n",
    "# print(actual_reshape_size_matrix.shape)\n",
    "# # print(scaled_preds_label.shape)\n",
    "# print(scaled_trues_label.shape)\n",
    "# print(train_list.shape)\n",
    "# print(pred_train.shape)\n",
    "# print(train_label.shape)\n",
    "\n",
    "# print(crop_image_matrix_val.shape)\n",
    "# print(actual_reshape_size_matrix_val.shape)\n",
    "\n",
    "# print(actual_reshape_size_matrix[0])\n",
    "# print(actual_reshape_size_matrix_val[0])\n",
    "# print(scaled_preds_label[0,0])\n",
    "# print(pred_train[0])\n",
    "# print(scaled_trues_label[0,0])\n",
    "# print(train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keras model\n",
    "# def build_cascade_model():\n",
    "#     base_model = applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(227,227, 3))\n",
    "#     last = base_model.output\n",
    "#     x = Flatten()(last)\n",
    "#     x = Dense(4096, activation='relu')(x)\n",
    "#     x = Dropout(0.7)(x)\n",
    "#     x = Dense(4096, activation='relu')(x)\n",
    "#     x = Dropout(0.7)(x)\n",
    "#     x = Dense(28, activation='relu')(x)\n",
    "#     preds = Reshape((2,14))(x)\n",
    "#     model = Model(base_model.input, preds)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # custom loss function (L2 distance)\n",
    "# def euclidean_distance_loss(y_true, y_pred):\n",
    "#     return K.sqrt(K.sum(K.square(y_pred - y_true)))/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_matrix = np.zeros((1600,2,14))\n",
    "# val_pred_matrix = np.zeros((200,2,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put model separately and have a test\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_images0 = crop_image_matrix[:,0]\n",
    "# temp_true_labels0 = scaled_trues_label[:,0,:]\n",
    "# temp_images_val = crop_image_matrix_val[:,0]\n",
    "# temp_true_labels0_val = scaled_trues_label_val[:,0,:]\n",
    "# cascade_model0 = build_cascade_model()\n",
    "# cascade_model0.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger = CSVLogger('stage2_0_v2.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "#     history = cascade_model0.fit(temp_images0, temp_true_labels0, epochs=50,batch_size=64,validation_data = (temp_images_val,temp_true_labels0_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model0.save('stage2_0_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "# temp_pred2_train0 = cascade_model0.predict(temp_images0) # (1600,2,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale back to original images to compute loss\n",
    "# temp_pred2_train0_store = temp_pred2_train0*actual_reshape_size_matrix/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_matrix[:,:,0] = temp_pred2_train0_store[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_val_images0 = crop_image_matrix_val[:,0]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "# temp_pred2_val0 = cascade_model0.predict(temp_val_images0) # (200,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_pred2_val0_store = temp_pred2_val0*actual_reshape_size_matrix_val/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pred_matrix[:,:,0] = temp_pred2_val0_store[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second joint\n",
    "# index = 1\n",
    "# temp_images1 = crop_image_matrix[:,index]\n",
    "# temp_true_labels1 = scaled_trues_label[:,index,:]\n",
    "# temp_images_val1 = crop_image_matrix_val[:,index]\n",
    "# temp_true_labels1_val = scaled_trues_label_val[:,index,:]\n",
    "# cascade_model1 = build_cascade_model()\n",
    "# cascade_model1.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger = CSVLogger('stage2_1_v2.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "#     history = cascade_model1.fit(temp_images1, temp_true_labels1, epochs=50,batch_size=64,validation_data = (temp_images_val1,temp_true_labels1_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model1.save('stage2_1_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_train1 = cascade_model1.predict(temp_images1) # (1600,2,1)\n",
    "# # scale back to original images to compute loss\n",
    "# temp_pred2_train1_store = temp_pred2_train1*actual_reshape_size_matrix/227\n",
    "# train_pred_matrix[:,:,index] = temp_pred2_train1_store[:,:,index]\n",
    "# temp_val_images1 = crop_image_matrix_val[:,index]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_val1 = cascade_model1.predict(temp_val_images1) # (200,2,1)\n",
    "# temp_pred2_val1_store = temp_pred2_val1*actual_reshape_size_matrix_val/227\n",
    "# val_pred_matrix[:,:,index] = temp_pred2_val1_store[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third joint\n",
    "# index = 2\n",
    "# temp_images2 = crop_image_matrix[:,index]\n",
    "# temp_true_labels2 = scaled_trues_label[:,index,:]\n",
    "# temp_images_val2 = crop_image_matrix_val[:,index]\n",
    "# temp_true_labels2_val = scaled_trues_label_val[:,index,:]\n",
    "# cascade_model2 = build_cascade_model()\n",
    "# cascade_model2.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger = CSVLogger('stage2_2_v2.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model2.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "#     cascade_model2.fit(temp_images2, temp_true_labels2, epochs=50,batch_size=64,validation_data = (temp_images_val2,temp_true_labels2_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model2.save('stage2_2_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_train2 = cascade_model2.predict(temp_images2) # (1600,2,1)\n",
    "# # scale back to original images to compute loss\n",
    "# temp_pred2_train2_store = temp_pred2_train2*actual_reshape_size_matrix/227\n",
    "# train_pred_matrix[:,:,index] = temp_pred2_train2_store[:,:,index]\n",
    "# temp_val_images2 = crop_image_matrix_val[:,index]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_val2 = cascade_model2.predict(temp_val_images2) # (200,2,1)\n",
    "# temp_pred2_val2_store = temp_pred2_val2*actual_reshape_size_matrix_val/227\n",
    "# val_pred_matrix[:,:,index] = temp_pred2_val2_store[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forth joint\n",
    "# index = 3\n",
    "# temp_images3 = crop_image_matrix[:,index]\n",
    "# temp_true_labels3 = scaled_trues_label[:,index,:]\n",
    "# temp_images_val3 = crop_image_matrix_val[:,index]\n",
    "# temp_true_labels3_val = scaled_trues_label_val[:,index,:]\n",
    "# cascade_model3 = build_cascade_model()\n",
    "# cascade_model3.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger = CSVLogger('stage2_3_v2.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "#     cascade_model3.fit(temp_images3, temp_true_labels3, epochs=50,batch_size=64,validation_data = (temp_images_val3,temp_true_labels3_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model3.save('stage2_3_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_train3 = cascade_model3.predict(temp_images3) # (1600,2,1)\n",
    "# # scale back to original images to compute loss\n",
    "# temp_pred2_train3_store = temp_pred2_train3*actual_reshape_size_matrix/227\n",
    "# train_pred_matrix[:,:,index] = temp_pred2_train3_store[:,:,index]\n",
    "# temp_val_images3 = crop_image_matrix_val[:,index]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_val3 = cascade_model3.predict(temp_val_images3) # (200,2,1)\n",
    "# temp_pred2_val3_store = temp_pred2_val3*actual_reshape_size_matrix_val/227\n",
    "# val_pred_matrix[:,:,index] = temp_pred2_val3_store[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth joint\n",
    "# index = 4\n",
    "# temp_images4 = crop_image_matrix[:,index]\n",
    "# temp_true_labels4 = scaled_trues_label[:,index,:]\n",
    "# temp_images_val4 = crop_image_matrix_val[:,index]\n",
    "# temp_true_labels4_val = scaled_trues_label_val[:,index,:]\n",
    "# cascade_model4 = build_cascade_model()\n",
    "# cascade_model4.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger = CSVLogger('stage2_4_v2.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "#     cascade_model4.fit(temp_images4, temp_true_labels4, epochs=50,batch_size=64,validation_data = (temp_images_val4,temp_true_labels4_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model4.save('stage2_4_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_train4 = cascade_model4.predict(temp_images4) # (1600,2,14)\n",
    "# # scale back to original images to compute loss\n",
    "# temp_pred2_train4_store = temp_pred2_train4*actual_reshape_size_matrix/227\n",
    "# train_pred_matrix[:,:,index] = temp_pred2_train4_store[:,:,index]\n",
    "# temp_val_images4 = crop_image_matrix_val[:,index]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_val4 = cascade_model4.predict(temp_val_images4) # (200,2,14)\n",
    "# temp_pred2_val4_store = temp_pred2_val4*actual_reshape_size_matrix_val/227\n",
    "# val_pred_matrix[:,:,index] = temp_pred2_val4_store[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth joint\n",
    "# index = 5\n",
    "# temp_images5 = crop_image_matrix[:,index]\n",
    "# temp_true_labels5 = scaled_trues_label[:,index,:]\n",
    "# temp_images_val5 = crop_image_matrix_val[:,index]\n",
    "# temp_true_labels5_val = scaled_trues_label_val[:,index,:]\n",
    "# cascade_model5 = build_cascade_model()\n",
    "# cascade_model5.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger = CSVLogger('stage2_5_v2.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "#     cascade_model5.fit(temp_images5, temp_true_labels5, epochs=50,batch_size=64,validation_data = (temp_images_val5,temp_true_labels5_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model5.save('stage2_5_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_train5 = cascade_model5.predict(temp_images5) # (1600,2,14)\n",
    "# # scale back to original images to compute loss\n",
    "# temp_pred2_train5_store = temp_pred2_train5*actual_reshape_size_matrix/227\n",
    "# train_pred_matrix[:,:,index] = temp_pred2_train5_store[:,:,index]\n",
    "# temp_val_images5 = crop_image_matrix_val[:,index]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_val5 = cascade_model5.predict(temp_val_images5) # (200,2,14)\n",
    "# temp_pred2_val5_store = temp_pred2_val5*actual_reshape_size_matrix_val/227\n",
    "# val_pred_matrix[:,:,index] = temp_pred2_val5_store[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seventh joint\n",
    "# index = 6\n",
    "# temp_images6 = crop_image_matrix[:,index]\n",
    "# temp_true_labels6 = scaled_trues_label[:,index,:]\n",
    "# temp_images_val6 = crop_image_matrix_val[:,index]\n",
    "# temp_true_labels6_val = scaled_trues_label_val[:,index,:]\n",
    "# cascade_model6 = build_cascade_model()\n",
    "# cascade_model6.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])\n",
    "# csv_logger = CSVLogger('stage2_6_v2.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "#     # fit the model\n",
    "#     cascade_model6.fit(temp_images6, temp_true_labels6, epochs=50,batch_size=64,validation_data = (temp_images_val6,temp_true_labels6_val),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model6.save('stage2_6_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_train6 = cascade_model6.predict(temp_images6) # (1600,2,14)\n",
    "# # scale back to original images to compute loss\n",
    "# temp_pred2_train6_store = temp_pred2_train6*actual_reshape_size_matrix/227\n",
    "# train_pred_matrix[:,:,index] = temp_pred2_train6_store[:,:,index]\n",
    "# temp_val_images6 = crop_image_matrix_val[:,index]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_val6 = cascade_model6.predict(temp_val_images6) # (200,2,14)\n",
    "# temp_pred2_val6_store = temp_pred2_val6*actual_reshape_size_matrix_val/227\n",
    "# val_pred_matrix[:,:,index] = temp_pred2_val6_store[:,:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eighth joint\n",
    "# index = 7\n",
    "# temp_images7 = crop_image_matrix[:,index]\n",
    "# temp_true_labels7 = scaled_trues_label[:,index,:,index,None]\n",
    "# cascade_model7 = build_cascade_model()\n",
    "# cascade_model7.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])\n",
    "# csv_logger = CSVLogger('stage2_7.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "#     # fit the model\n",
    "#     cascade_model7.fit(temp_images7, temp_true_labels7, epochs=50,batch_size=64,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model7.save('stage2_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_train7 = cascade_model7.predict(temp_images7) # (1600,2,1)\n",
    "# # scale back to original images to compute loss\n",
    "# train_pred_matrix[:,:,index,None] = temp_pred2_train7*actual_reshape_size_matrix[:,:,index,None]/227\n",
    "\n",
    "# temp_val_images7 = crop_image_matrix_val[:,index]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_val7 = cascade_model7.predict(temp_val_images7) # (200,2,1)\n",
    "# val_pred_matrix[:,:,index,None] = temp_pred2_val7*actual_reshape_size_matrix_val[:,:,index,None]/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ninth joint\n",
    "# index = 8\n",
    "# temp_images7 = crop_image_matrix[:,index]\n",
    "# temp_true_labels8 = scaled_trues_label[:,index,:,index,None]\n",
    "# cascade_model8 = build_cascade_model()\n",
    "# cascade_model8.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])\n",
    "# csv_logger = CSVLogger('stage2_8.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "#     # fit the model\n",
    "#     cascade_model8.fit(temp_images8, temp_true_labels8, epochs=50,batch_size=64,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade_model7.save('stage2_7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_train8 = cascade_model8.predict(temp_images8) # (1600,2,1)\n",
    "# # scale back to original images to compute loss\n",
    "# train_pred_matrix[:,:,index,None] = temp_pred2_train8*actual_reshape_size_matrix[:,:,index,None]/227\n",
    "\n",
    "# temp_val_images8 = crop_image_matrix_val[:,index]\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     temp_pred2_val8 = cascade_model8.predict(temp_val_images8) # (200,2,1)\n",
    "# val_pred_matrix[:,:,index,None] = temp_pred2_val8*actual_reshape_size_matrix_val[:,:,index,None]/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code put every model together\n",
    "# epoches = 10\n",
    "# train_pred_matrix = np.zeros((1600,2,14))\n",
    "# val_pred_matrix = np.zeros((200,2,14))\n",
    "# for epoch in range(epoches):\n",
    "    \n",
    "#     for i in range(14):\n",
    "        \n",
    "#         # prepare the data\n",
    "#         # crop_image_matrix (1600,14,227,227,3) => (1600,227,227,3) extract all images belong to one specific bounding box\n",
    "#         temp_images = crop_image_matrix[:,i]\n",
    "#         # scaled trues label (1600,14,2,14) => (1600,i,2,i) => (1600,2,1)\n",
    "#         temp_true_labels = scaled_trues_label[:,i,:,i,None]\n",
    "        \n",
    "#         # create the model\n",
    "#         cascade_model = build_cascade_model()\n",
    "        \n",
    "#         # compile the model\n",
    "#         cascade_model.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])\n",
    "        \n",
    "#         with tf.device('/device:GPU:0'):\n",
    "#             # fit the model\n",
    "#             history = cascade_model.fit(temp_images, temp_true_labels, epochs=1,batch_size=64)\n",
    "        \n",
    "#         # store training prediction\n",
    "#         with tf.device('/device:GPU:0'):\n",
    "#             temp_pred2_train = cascade_model.predict(temp_images) # (1600,2,1)\n",
    "        \n",
    "#         # scale back to original images to compute loss\n",
    "#         temp_train_pred2 = temp_pred2_train*actual_reshape_size_matrix[:,:,i,None]/227\n",
    "        \n",
    "#         train_pred_matrix[:,:,i,None] = temp_train_pred2\n",
    "        \n",
    "#         # store validation prediction\n",
    "        \n",
    "#         temp_val_images = crop_image_matrix_val[:,i]\n",
    "#         with tf.device('/device:GPU:0'):\n",
    "#             temp_pred2_val = cascade_model.predict(temp_val_images) # (200,2,1)\n",
    "            \n",
    "#         temp_val_pred2 = temp_pred2_val*actual_reshape_size_matrix_val[:,:,i,None]/227\n",
    "        \n",
    "#         val_pred_matrix[:,:,i,None] = temp_val_pred2\n",
    "        \n",
    "        \n",
    "#     temp_train_loss = K.sqrt(K.sum(K.square(train_pred_matrix - train_label)))/1600\n",
    "        \n",
    "#     print( 'training loss is ', temp_train_loss)\n",
    "    \n",
    "#     temp_val_loss = K.sqrt(K.sum(K.square(val_pred_matrix - val_label)))/200\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
