{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.image as img\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from os.path import basename as b\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the image to 227*227*3 since this is the input size for alexnet\n",
    "def prepare_image(original_image_path):\n",
    "    image = misc.imread(original_image_path)\n",
    "    # scale the image to 227*227\n",
    "    scaled_image = misc.imresize(image, (227, 227), interp='bicubic')\n",
    "    return scaled_image, image.shape[0], image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the label accordingly. Notice label[0] should be rescaled by width\n",
    "# label[1] should be rescaled by height. I guess this is what we should do (might reverse width and height? if the output is not good)\n",
    "# refer to: https://github.com/samitok/deeppose/blob/master/Codes/Original/GetLSPData.py scale_label function\n",
    "def scale_label(label, original_height, original_width):\n",
    "    label[0, :] *= (227 / float(original_width))\n",
    "    label[1,:] *= (227 / float(original_height))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each image x has shape 227*227*3, each label y has shape 3*14 \n",
    "# each image_list contains num_examples images. Each label_list contains num_examples labels\n",
    "# image_list[i] has label label_list[i]\n",
    "def generate_dataset(image_paths,labels,dataset):\n",
    "    num_examples = image_paths.shape[0]\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    print('Start to process '+ dataset + ' dataset')\n",
    "    for index in range(num_examples):\n",
    "        image, or_height, or_width = prepare_image(image_paths[index])\n",
    "        image_list.append(image)\n",
    "        label = scale_label(labels[index], or_height, or_width)\n",
    "        # only extract x and y coordinates since z is 0 for all data\n",
    "        label_xy = label[0:2, :]\n",
    "        label_list.append(label_xy)\n",
    "    print('Done processing the ' + dataset + ' dataset')\n",
    "    return np.array(image_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train,val,test dataset\n",
    "def getLSPDataset(train_set_ratio=0.8,validation_set_ratio = 0.1):\n",
    "    print('Resizing and packing images and labels to lists.\\n')\n",
    "    np.random.seed(1701)  # to fix test set\n",
    "    # load the dataset. Make sure you put the joints.mat in the same folder as this .ipynb or .py program\n",
    "    # otherwise you can change the path here\n",
    "    joints = loadmat('/home/oceanland/lsp_dataset/joints.mat')\n",
    "    # transpose the shape to N*C*number of features, in this case it is 2000*3*14\n",
    "    joints = joints['joints'].transpose(2, 0, 1)\n",
    "    \n",
    "    # I saw some code such as this one: https://github.com/samitok/deeppose/blob/master/Codes/Original/GetLSPData.py only extracts two joints\n",
    "    # which is Right ankle and Right knee\n",
    "    # this one as well: https://github.com/mitmul/deeppose/blob/master/datasets/lsp_dataset.py\n",
    "    # invisible_joints = joints[:, :, 2] < 0.5\n",
    "    # joints[invisible_joints] = 0\n",
    "    # joints = joints[..., :2]\n",
    "    \n",
    "    # get the list of images names. Make sure you put the images directory in the same folder as this .ipynb or .py program\n",
    "    # otherwise you can change the path here\n",
    "    image_list = np.asarray(sorted(glob.glob('/home/oceanland/lsp_dataset/images/*.jpg')))\n",
    "    \n",
    "    # get image indexes\n",
    "    image_indexes = list(range(0, len(image_list)))\n",
    "    \n",
    "    # random shuffle the data\n",
    "    # shuffle the index and use the indexes to select images. So it is equivalent to shuffle images\n",
    "    np.random.shuffle(image_indexes)\n",
    "\n",
    "   \n",
    "    # get the training, val and test set indexes\n",
    "    train_validation_split = int(len(image_list)*train_set_ratio)\n",
    "    validation_test_split = int(len(image_list)*(train_set_ratio+validation_set_ratio))\n",
    "    train_indexes = np.asarray(image_indexes[:train_validation_split])\n",
    "    validation_indexes = np.asarray(image_indexes[train_validation_split:validation_test_split])\n",
    "    test_indexes = np.asarray(image_indexes[validation_test_split:])\n",
    "\n",
    "    # generate label\n",
    "    train_list,train_label = generate_dataset(image_list[train_indexes],joints[train_indexes],'training')\n",
    "    val_list,val_label = generate_dataset(image_list[validation_indexes],joints[validation_indexes],'validation')\n",
    "    test_list,test_label = generate_dataset(image_list[test_indexes],joints[test_indexes],'test')\n",
    "    \n",
    "    return train_list,train_label,val_list,val_label,test_list,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing and packing images and labels to lists.\n",
      "\n",
      "/home/oceanland/lsp_dataset/images/im0026.jpg\n",
      "[[108.39052677  84.32845509  58.17402934  80.14374697  96.67334404\n",
      "   66.54344558  35.36737008  38.29666577  55.87243987  87.67622158\n",
      "  108.39052677 124.08318222  77.00521588  78.88833453]\n",
      " [145.38521527 103.53813407  91.19324512  90.98400972 124.88014549\n",
      "  162.33328316  87.84547863  73.40823561  52.27545961  48.92769311\n",
      "   73.19900021  78.84835617  46.41686824  25.07485683]\n",
      " [  0.           0.           0.           0.           1.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]]\n",
      "1867\n",
      "25\n",
      "/home/oceanland/lsp_dataset/images/im0026.jpg\n",
      "[[108.39052677  84.32845509  58.17402934  80.14374697  96.67334404\n",
      "   66.54344558  35.36737008  38.29666577  55.87243987  87.67622158\n",
      "  108.39052677 124.08318222  77.00521588  78.88833453]\n",
      " [145.38521527 103.53813407  91.19324512  90.98400972 124.88014549\n",
      "  162.33328316  87.84547863  73.40823561  52.27545961  48.92769311\n",
      "   73.19900021  78.84835617  46.41686824  25.07485683]\n",
      " [  0.           0.           0.           0.           1.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]]\n",
      "Start to process training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing the training dataset\n",
      "Start to process validation dataset\n",
      "Done processing the validation dataset\n",
      "Start to process test dataset\n",
      "Done processing the test dataset\n"
     ]
    }
   ],
   "source": [
    "train_list,train_label,val_list,val_label,test_list,test_label = getLSPDataset(train_set_ratio=0.99,validation_set_ratio = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "print(val_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 2, 14)\n"
     ]
    }
   ],
   "source": [
    "print(val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49.52750102  73.15711876  73.15711876 117.79084116 141.4204589\n",
      "  157.1735374  165.05007665 104.66327575  91.53571034 149.29699815\n",
      "  149.29699815 172.92661589 133.54391966 154.54802432]\n",
      " [201.09109584 157.59147081 109.12046006 111.60615291 157.59147081\n",
      "  196.11971013 109.12046006  90.47776361  56.92091001  61.89229573\n",
      "   94.2063029  109.12046006  46.97813858  23.36405642]]\n"
     ]
    }
   ],
   "source": [
    "print(val_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
