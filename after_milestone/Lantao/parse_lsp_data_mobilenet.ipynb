{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.image as img\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from os.path import basename as b\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the image to 227*227*3 since this is the input size for alexnet\n",
    "def prepare_image(original_image_path):\n",
    "    image = misc.imread(original_image_path)\n",
    "    # scale the image to 227*227\n",
    "    scaled_image = misc.imresize(image, (224, 224), interp='bicubic')\n",
    "    return scaled_image, image.shape[0], image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the label accordingly. Notice label[0] should be rescaled by width\n",
    "# label[1] should be rescaled by height. I guess this is what we should do (might reverse width and height? if the output is not good)\n",
    "# refer to: https://github.com/samitok/deeppose/blob/master/Codes/Original/GetLSPData.py scale_label function\n",
    "def scale_label(label, original_height, original_width):\n",
    "    label[0, :] *= (224 / float(original_width))\n",
    "    label[1,:] *= (224 / float(original_height))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each image x has shape 227*227*3, each label y has shape 3*14 \n",
    "# each image_list contains num_examples images. Each label_list contains num_examples labels\n",
    "# image_list[i] has label label_list[i]\n",
    "def generate_dataset(image_paths,labels,dataset):\n",
    "    num_examples = image_paths.shape[0]\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    print('Start to process '+ dataset + ' dataset')\n",
    "    for index in range(num_examples):\n",
    "        image, or_height, or_width = prepare_image(image_paths[index])\n",
    "        image_list.append(image)\n",
    "        label = scale_label(labels[index], or_height, or_width)\n",
    "        # only extract x and y coordinates since z is 0 for all data\n",
    "        label_xy = label[0:2, :]\n",
    "        label_list.append(label_xy)\n",
    "    print('Done processing the ' + dataset + ' dataset')\n",
    "    return np.array(image_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train,val,test dataset\n",
    "def getLSPDataset(train_set_ratio=0.8,validation_set_ratio = 0.1):\n",
    "    print('Resizing and packing images and labels to lists.\\n')\n",
    "    np.random.seed(1701)  # to fix test set\n",
    "    # load the dataset. Make sure you put the joints.mat in the same folder as this .ipynb or .py program\n",
    "    # otherwise you can change the path here\n",
    "    joints = loadmat('/home/oceanland/lsp_dataset/joints.mat')\n",
    "    # transpose the shape to N*C*number of features, in this case it is 2000*3*14\n",
    "    joints = joints['joints'].transpose(2, 0, 1)\n",
    "    \n",
    "    # I saw some code such as this one: https://github.com/samitok/deeppose/blob/master/Codes/Original/GetLSPData.py only extracts two joints\n",
    "    # which is Right ankle and Right knee\n",
    "    # this one as well: https://github.com/mitmul/deeppose/blob/master/datasets/lsp_dataset.py\n",
    "    # invisible_joints = joints[:, :, 2] < 0.5\n",
    "    # joints[invisible_joints] = 0\n",
    "    # joints = joints[..., :2]\n",
    "    \n",
    "    # get the list of images names. Make sure you put the images directory in the same folder as this .ipynb or .py program\n",
    "    # otherwise you can change the path here\n",
    "    image_list = np.asarray(sorted(glob.glob('/home/oceanland/lsp_dataset/images/*.jpg')))\n",
    "    \n",
    "    # get image indexes\n",
    "    image_indexes = list(range(0, len(image_list)))\n",
    "    \n",
    "    # random shuffle the data\n",
    "    # shuffle the index and use the indexes to select images. So it is equivalent to shuffle images\n",
    "    np.random.shuffle(image_indexes)\n",
    "\n",
    "   \n",
    "    # get the training, val and test set indexes\n",
    "    train_validation_split = int(len(image_list)*train_set_ratio)\n",
    "    validation_test_split = int(len(image_list)*(train_set_ratio+validation_set_ratio))\n",
    "    train_indexes = np.asarray(image_indexes[:train_validation_split])\n",
    "    validation_indexes = np.asarray(image_indexes[train_validation_split:validation_test_split])\n",
    "    test_indexes = np.asarray(image_indexes[validation_test_split:])\n",
    "\n",
    "    # generate label\n",
    "    train_list,train_label = generate_dataset(image_list[train_indexes],joints[train_indexes],'training')\n",
    "    val_list,val_label = generate_dataset(image_list[validation_indexes],joints[validation_indexes],'validation')\n",
    "    test_list,test_label = generate_dataset(image_list[test_indexes],joints[test_indexes],'test')\n",
    "    \n",
    "    return train_list,train_label,val_list,val_label,test_list,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing and packing images and labels to lists.\n",
      "\n",
      "Start to process training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing the training dataset\n",
      "Start to process validation dataset\n",
      "Done processing the validation dataset\n",
      "Start to process test dataset\n",
      "Done processing the test dataset\n"
     ]
    }
   ],
   "source": [
    "train_list,train_label,val_list,val_label,test_list,test_label = getLSPDataset(train_set_ratio=0.99,validation_set_ratio = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(val_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 14)\n"
     ]
    }
   ],
   "source": [
    "print(val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68.44842726 102.76388604  83.36819195  58.75058022  72.92435667\n",
      "   84.86016842 172.14079182 127.38149777 101.27190957  49.05273317\n",
      "   71.4323802  153.49108596  89.33609782 105.74783897]\n",
      " [199.67742478 156.08787559 114.24190837 113.89319198 157.13402477\n",
      "  200.37485757 112.8470428   91.2266264   64.02674771  49.72937557\n",
      "   68.21134443  59.84215098  43.80119688  22.87821327]]\n"
     ]
    }
   ],
   "source": [
    "print(val_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
