{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from parse_lsp_data import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model,Input\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout,Reshape\n",
    "from keras.optimizers import SGD,Adam\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten,Activation, Average,GlobalAveragePooling2D\n",
    "from image_noise_generation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data set\n",
    "train_list, train_label, val_list, val_label, test_list, test_label = getLSPDataset(0.8, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some information\n",
    "train_X = train_list\t# (N, 227, 227, 3)\n",
    "train_Y = train_label\t# (N, 2, 14)\n",
    "train_X,train_Y = data_augmentation(train_X,train_Y)\n",
    "print(\"train X: \", train_X.shape, \"val X: \", val_list.shape, \"test X: \", test_list.shape)\n",
    "print(\"train Y: \", train_Y.shape, \"val Y: \", val_label.shape, \"test Y: \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_input = Input(shape=(227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keras model\n",
    "def build_model():\n",
    "    base_model = applications.densenet.DenseNet121(weights='imagenet', include_top=False, input_shape=(227,227, 3))\n",
    "    last = base_model.output\n",
    "    x = Flatten()(last)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.9)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.9)(x)\n",
    "    x = Dense(28, activation='relu')(x)\n",
    "    preds = Reshape((2,14))(x)\n",
    "    model = Model(base_model.input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function (L2 distance)\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true)))/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "def accuracy(y_true, y_pred):\n",
    "    \n",
    "    diff = K.square(y_true - y_pred)\n",
    "#     loss = K.sum(diff)\n",
    "    dist = K.sqrt(K.sum(diff, axis = 1))\t# (N, 2, 14) -> (N, 14)\n",
    "#     accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 8/14\n",
    "    torsor_xy = y_true[:,:,9] - y_true[:,:,2] # (N,2)\n",
    "    torsor_dist = K.sqrt(K.sum(K.square(torsor_xy),axis=1,keepdims=True)) #(N,1)\n",
    "    torsor_frac = thresh*torsor_dist\n",
    "    \n",
    "    accuracy = K.sum(K.cast(K.greater(torsor_frac,dist),dtype='float32'))/64/14\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=Adam(lr=0.00005), loss=euclidean_distance_loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('densenet121_t05_lrxingxing_dp09.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history = model.fit(train_X, train_Y, epochs=100,batch_size=64, validation_data = (val_list,val_label),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "with tf.device('/device:GPU:0'):\n",
    "    loss,acc = model.evaluate(test_list, test_label,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    pred = model.predict(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[0])\n",
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = K.sqrt(K.sum(K.square(pred[0] - test_label[0]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.array(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.reduce_sum(tf.to_int32(tf.greater(threshold, dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('densenet121_t05_lrxingxing_dp09.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "def load_trained_model(weights_path):\n",
    "    model = build_model()\n",
    "    model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model('densenet121_t05_lrxingxing_dp09.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.00005), loss=euclidean_distance_loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred2 = train_model.predict(train_list)\n",
    "pred2 = model.predict(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred3 = train_model.predict(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage:\n",
    "# drawLines(val_list[5].copy(),val_label[5].copy(),pred3[5].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from drawLines_v2 import drawLines\n",
    "# usage:\n",
    "index = 6\n",
    "drawLines(test_list[index].copy(),test_label[index].copy(),pred[index].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage:\n",
    "index2 = 0\n",
    "drawLines(train_list[index2].copy(),train_label[index2].copy(),pred2[index2].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "def load_trained_model(weights_path):\n",
    "    model = build_model()\n",
    "    model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model('resnet50_t05_lr00005.h5')\n",
    "model.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade\n",
    "with tf.device('/device:GPU:0'):\n",
    "    pred = model.predict(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    pred_val = model.predict(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crop_image_keras import images_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_image_matrix,actual_reshape_size_matrix,scaled_preds_label,scaled_trues_label = images_crop(train_list.copy(),pred.copy(),train_label.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_image_matrix_val,actual_reshape_size_matrix_val,_,_ = images_crop(val_list.copy(),pred_val.copy(),val_label.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crop_image_matrix.shape)\n",
    "print(actual_reshape_size_matrix.shape)\n",
    "print(scaled_preds_label.shape)\n",
    "print(scaled_trues_label.shape)\n",
    "print(train_list.shape)\n",
    "print(pred.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(crop_image_matrix_val.shape)\n",
    "print(actual_reshape_size_matrix_val.shape)\n",
    "\n",
    "print(actual_reshape_size_matrix[0])\n",
    "print(actual_reshape_size_matrix_val[0])\n",
    "print(scaled_preds_label[0,0])\n",
    "print(scaled_trues_label[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # just a quick check my scale computation\n",
    "# print(train_label[0])\n",
    "# # print(pred[0])\n",
    "# print(actual_reshape_size_matrix[0])\n",
    "# # print(scaled_preds_label[0,0])\n",
    "# print(scaled_trues_label[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keras model\n",
    "def build_cascade_model():\n",
    "    base_model = applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(227,227, 3))\n",
    "    last = base_model.output\n",
    "    x = Flatten()(last)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(2, activation='relu')(x)\n",
    "    preds = Reshape((2,1))(x)\n",
    "    model = Model(base_model.input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function (L2 distance)\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true)))/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_matrix = np.zeros((1600,2,14))\n",
    "val_pred_matrix = np.zeros((200,2,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put model separately and have a test\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_images0 = crop_image_matrix[:,0]\n",
    "temp_true_labels0 = scaled_trues_label[:,0,:,0,None]\n",
    "cascade_model0 = build_cascade_model()\n",
    "cascade_model0.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history = cascade_model0.fit(temp_images0, temp_true_labels0, epochs=50,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train0 = cascade_model0.predict(temp_images0) # (1600,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale back to original images to compute loss\n",
    "temp_pred2_train0_store = temp_pred2_train0*actual_reshape_size_matrix[:,:,0,None]/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_matrix[:,:,0,None] = temp_pred2_train0_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val_images0 = crop_image_matrix_val[:,0]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val0 = cascade_model0.predict(temp_val_images0) # (200,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pred2_val0_store = temp_pred2_val0*actual_reshape_size_matrix_val[:,:,0,None]/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_matrix[:,:,0,None] = temp_pred2_val0_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second joint\n",
    "index = 1\n",
    "temp_images1 = crop_image_matrix[:,index]\n",
    "temp_true_labels1 = scaled_trues_label[:,index,:,index,None]\n",
    "cascade_model1 = build_cascade_model()\n",
    "cascade_model1.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history = cascade_model1.fit(temp_images1, temp_true_labels1, epochs=50,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train1 = cascade_model1.predict(temp_images1) # (1600,2,1)\n",
    "# scale back to original images to compute loss\n",
    "temp_pred2_train1_store = temp_pred2_train1*actual_reshape_size_matrix[:,:,index,None]/227\n",
    "train_pred_matrix[:,:,index,None] = temp_pred2_train1_store\n",
    "temp_val_images1 = crop_image_matrix_val[:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val1 = cascade_model1.predict(temp_val_images1) # (200,2,1)\n",
    "temp_pred2_val1_store = temp_pred2_val1*actual_reshape_size_matrix_val[:,:,index,None]/227\n",
    "val_pred_matrix[:,:,index,None] = temp_pred2_val1_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third joint\n",
    "index = 2\n",
    "temp_images2 = crop_image_matrix[:,index]\n",
    "temp_true_labels2 = scaled_trues_label[:,index,:,index,None]\n",
    "cascade_model2 = build_cascade_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_model2.compile(optimizer=Adam(lr=1), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history = cascade_model2.fit(temp_images2, temp_true_labels2, epochs=50,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train2 = cascade_model2.predict(temp_images2) # (1600,2,1)\n",
    "# scale back to original images to compute loss\n",
    "train_pred_matrix[:,:,index,None] = temp_pred2_train2*actual_reshape_size_matrix[:,:,index,None]/227\n",
    "\n",
    "temp_val_images2 = crop_image_matrix_val[:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val2 = cascade_model2.predict(temp_val_images2) # (200,2,1)\n",
    "val_pred_matrix[:,:,index,None] = temp_pred2_val2*actual_reshape_size_matrix_val[:,:,index,None]/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forth joint\n",
    "index = 3\n",
    "temp_images3 = crop_image_matrix[:,index]\n",
    "temp_true_labels3 = scaled_trues_label[:,index,:,index,None]\n",
    "cascade_model3 = build_cascade_model()\n",
    "cascade_model3.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history3 = cascade_model3.fit(temp_images3, temp_true_labels3, epochs=50,batch_size=64,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train3 = cascade_model3.predict(temp_images3) # (1600,2,1)\n",
    "# scale back to original images to compute loss\n",
    "train_pred_matrix[:,:,index,None] = temp_pred2_train3*actual_reshape_size_matrix[:,:,index,None]/227\n",
    "\n",
    "temp_val_images3 = crop_image_matrix_val[:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val3 = cascade_model3.predict(temp_val_images3) # (200,2,1)\n",
    "val_pred_matrix[:,:,index,None] = temp_pred2_val3*actual_reshape_size_matrix_val[:,:,index,None]/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth joint\n",
    "index = 3\n",
    "temp_images4 = crop_image_matrix[:,index]\n",
    "temp_true_labels4 = scaled_trues_label[:,index,:,index,None]\n",
    "cascade_model4 = build_cascade_model()\n",
    "cascade_model4.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history = cascade_model4.fit(temp_images4, temp_true_labels4, epochs=50,batch_size=64,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training prediction\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_train4 = cascade_model4.predict(temp_images4) # (1600,2,1)\n",
    "# scale back to original images to compute loss\n",
    "train_pred_matrix[:,:,index,None] = temp_pred2_train4*actual_reshape_size_matrix[:,:,index,None]/227\n",
    "\n",
    "temp_val_images4 = crop_image_matrix_val[:,index]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    temp_pred2_val4 = cascade_model4.predict(temp_val_images4) # (200,2,1)\n",
    "val_pred_matrix[:,:,index,None] = temp_pred2_val4*actual_reshape_size_matrix_val[:,:,index,None]/227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code put every model together\n",
    "epoches = 10\n",
    "train_pred_matrix = np.zeros((1600,2,14))\n",
    "val_pred_matrix = np.zeros((200,2,14))\n",
    "for epoch in range(epoches):\n",
    "    \n",
    "    for i in range(14):\n",
    "        \n",
    "        # prepare the data\n",
    "        # crop_image_matrix (1600,14,227,227,3) => (1600,227,227,3) extract all images belong to one specific bounding box\n",
    "        temp_images = crop_image_matrix[:,i]\n",
    "        # scaled trues label (1600,14,2,14) => (1600,i,2,i) => (1600,2,1)\n",
    "        temp_true_labels = scaled_trues_label[:,i,:,i,None]\n",
    "        \n",
    "        # create the model\n",
    "        cascade_model = build_cascade_model()\n",
    "        \n",
    "        # compile the model\n",
    "        cascade_model.compile(optimizer=Adam(lr=0.0005), loss=euclidean_distance_loss, metrics=[])\n",
    "        \n",
    "        with tf.device('/device:GPU:0'):\n",
    "            # fit the model\n",
    "            history = cascade_model.fit(temp_images, temp_true_labels, epochs=1,batch_size=64)\n",
    "        \n",
    "        # store training prediction\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            temp_pred2_train = cascade_model.predict(temp_images) # (1600,2,1)\n",
    "        \n",
    "        # scale back to original images to compute loss\n",
    "        temp_train_pred2 = temp_pred2_train*actual_reshape_size_matrix[:,:,i,None]/227\n",
    "        \n",
    "        train_pred_matrix[:,:,i,None] = temp_train_pred2\n",
    "        \n",
    "        # store validation prediction\n",
    "        \n",
    "        temp_val_images = crop_image_matrix_val[:,i]\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            temp_pred2_val = cascade_model.predict(temp_val_images) # (200,2,1)\n",
    "            \n",
    "        temp_val_pred2 = temp_pred2_val*actual_reshape_size_matrix_val[:,:,i,None]/227\n",
    "        \n",
    "        val_pred_matrix[:,:,i,None] = temp_val_pred2\n",
    "        \n",
    "        \n",
    "    temp_train_loss = K.sqrt(K.sum(K.square(train_pred_matrix - train_label)))/1600\n",
    "        \n",
    "    print( 'training loss is ', temp_train_loss)\n",
    "    \n",
    "    temp_val_loss = K.sqrt(K.sum(K.square(val_pred_matrix - val_label)))/200\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
