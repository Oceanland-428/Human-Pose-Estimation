{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from parse_lsp_data import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model,Input\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout,Reshape\n",
    "from keras.optimizers import SGD,Adam\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten,Activation, Average,GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2150996135503141571\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing and packing images and labels to lists.\n",
      "\n",
      "Start to process training dataset\n",
      "Done processing the training dataset\n",
      "Start to process validation dataset\n",
      "Done processing the validation dataset\n",
      "Start to process test dataset\n",
      "Done processing the test dataset\n"
     ]
    }
   ],
   "source": [
    "# get the data set\n",
    "train_list, train_label, val_list, val_label, test_list, test_label = getLSPDataset(0.8, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X:  (1600, 227, 227, 3) val X:  (200, 227, 227, 3) test X:  (200, 227, 227, 3)\n",
      "train Y:  (1600, 2, 14) val Y:  (200, 2, 14) test Y:  (200, 2, 14)\n"
     ]
    }
   ],
   "source": [
    "# print some information\n",
    "train_X = train_list\t# (N, 227, 227, 3)\n",
    "train_Y = train_label\t# (N, 2, 14)\n",
    "print(\"train X: \", train_list.shape, \"val X: \", val_list.shape, \"test X: \", test_list.shape)\n",
    "print(\"train Y: \", train_label.shape, \"val Y: \", val_label.shape, \"test Y: \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_input = Input(shape=(227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keras model\n",
    "def build_model():\n",
    "#     # Block 1\n",
    "#     x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(model_input)\n",
    "#     x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "#     x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "#     # Block 2\n",
    "#     x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "#     x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "#     x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "#     # Block 3\n",
    "#     x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "#     x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "#     x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "#     x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "#     # Block 4\n",
    "#     x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "#     x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "#     x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "#     x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "#     # Block 5\n",
    "#     x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "#     x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "#     x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "#     x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "#     x = Flatten(name='flatten')(x)\n",
    "#     x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "#     x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "#     x = Dense(28, activation='relu', name='fc3')(x)\n",
    "#     x = Reshape((2,14))(x)\n",
    "#     model = Model(model_input, x, name='vgg16')\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(227,227, 3))\n",
    "    last = base_model.output\n",
    "    x = Flatten()(last)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dense(28, activation='relu')(x)\n",
    "    preds = Reshape((2,14))(x)\n",
    "    model = Model(base_model.input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function (L2 distance)\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_accuracy(y_true, y_pred):\n",
    "    diff = tf.square(y_true - y_pred)\n",
    "    loss = tf.reduce_sum(diff)\n",
    "    dist = tf.sqrt(tf.reduce_sum(diff, axis = 1))\t# (N, 2, 14) -> (N, 14)\n",
    "    accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 128/14\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss=euclidean_distance_loss, metrics=[loss_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('logvgg_temp.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 36s 23ms/step - loss: 170.3901 - loss_accuracy: 2.2321e-04 - val_loss: 216.3692 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 113.6698 - loss_accuracy: 2.0089e-04 - val_loss: 191.7068 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 104.7751 - loss_accuracy: 6.9196e-04 - val_loss: 129.7079 - val_loss_accuracy: 1.7857e-04\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 101.6837 - loss_accuracy: 6.4732e-04 - val_loss: 105.0358 - val_loss_accuracy: 3.5714e-04\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 90.1829 - loss_accuracy: 9.1518e-04 - val_loss: 118.7286 - val_loss_accuracy: 0.0013\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 83.6011 - loss_accuracy: 9.3750e-04 - val_loss: 106.6133 - val_loss_accuracy: 3.5714e-04\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 77.9096 - loss_accuracy: 9.1518e-04 - val_loss: 125.9960 - val_loss_accuracy: 1.7857e-04\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 71.7734 - loss_accuracy: 0.0012 - val_loss: 120.8244 - val_loss_accuracy: 1.7857e-04\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 68.6534 - loss_accuracy: 0.0017 - val_loss: 103.5596 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 65.5133 - loss_accuracy: 0.0017 - val_loss: 101.8936 - val_loss_accuracy: 5.3571e-04\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 61.7077 - loss_accuracy: 0.0018 - val_loss: 90.6053 - val_loss_accuracy: 0.0016\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 60.0157 - loss_accuracy: 0.0016 - val_loss: 97.7145 - val_loss_accuracy: 1.7857e-04\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 56.2864 - loss_accuracy: 0.0023 - val_loss: 92.2285 - val_loss_accuracy: 1.7857e-04\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 54.8563 - loss_accuracy: 0.0020 - val_loss: 82.7420 - val_loss_accuracy: 0.0012\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 59.2683 - loss_accuracy: 0.0015 - val_loss: 75.3741 - val_loss_accuracy: 5.3571e-04\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 50.1069 - loss_accuracy: 0.0026 - val_loss: 93.0715 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 45.8945 - loss_accuracy: 0.0034 - val_loss: 79.8686 - val_loss_accuracy: 0.0014\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 44.4163 - loss_accuracy: 0.0031 - val_loss: 78.3160 - val_loss_accuracy: 3.5714e-04\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 42.9619 - loss_accuracy: 0.0033 - val_loss: 94.0212 - val_loss_accuracy: 1.7857e-04\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 51.0129 - loss_accuracy: 0.0018 - val_loss: 80.8518 - val_loss_accuracy: 5.5804e-04\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 49.4512 - loss_accuracy: 0.0019 - val_loss: 73.2940 - val_loss_accuracy: 7.3661e-04\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 42.5143 - loss_accuracy: 0.0031 - val_loss: 77.0333 - val_loss_accuracy: 3.5714e-04\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 38.6319 - loss_accuracy: 0.0037 - val_loss: 69.0408 - val_loss_accuracy: 0.0012\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 38.3998 - loss_accuracy: 0.0039 - val_loss: 71.5602 - val_loss_accuracy: 0.0013\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 36.3387 - loss_accuracy: 0.0043 - val_loss: 73.7354 - val_loss_accuracy: 0.0020\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 36.3748 - loss_accuracy: 0.0034 - val_loss: 79.8087 - val_loss_accuracy: 5.3571e-04\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 35.0957 - loss_accuracy: 0.0034 - val_loss: 82.9100 - val_loss_accuracy: 0.0011\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 34.8801 - loss_accuracy: 0.0042 - val_loss: 66.9626 - val_loss_accuracy: 0.0023\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 36.9558 - loss_accuracy: 0.0031 - val_loss: 66.9186 - val_loss_accuracy: 0.0036\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 34.3518 - loss_accuracy: 0.0038 - val_loss: 70.5046 - val_loss_accuracy: 8.9286e-04\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 32.8577 - loss_accuracy: 0.0044 - val_loss: 76.2785 - val_loss_accuracy: 5.3571e-04\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 32.5885 - loss_accuracy: 0.0045 - val_loss: 72.4865 - val_loss_accuracy: 0.0015\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 30.4523 - loss_accuracy: 0.0057 - val_loss: 68.0403 - val_loss_accuracy: 0.0025\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 31.5814 - loss_accuracy: 0.0050 - val_loss: 67.4675 - val_loss_accuracy: 0.0015\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 29.6438 - loss_accuracy: 0.0057 - val_loss: 78.6271 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 33.9068 - loss_accuracy: 0.0035 - val_loss: 71.7518 - val_loss_accuracy: 3.5714e-04\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 31.4320 - loss_accuracy: 0.0051 - val_loss: 81.7479 - val_loss_accuracy: 5.3571e-04\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 32.2681 - loss_accuracy: 0.0050 - val_loss: 69.9991 - val_loss_accuracy: 0.0025\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 28.7820 - loss_accuracy: 0.0065 - val_loss: 64.5516 - val_loss_accuracy: 0.0060\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 28.4546 - loss_accuracy: 0.0057 - val_loss: 70.6975 - val_loss_accuracy: 0.0013\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 28.8978 - loss_accuracy: 0.0062 - val_loss: 75.9167 - val_loss_accuracy: 8.9286e-04\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 27.5569 - loss_accuracy: 0.0059 - val_loss: 69.1281 - val_loss_accuracy: 0.0011\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 25.4448 - loss_accuracy: 0.0083 - val_loss: 68.9532 - val_loss_accuracy: 0.0012\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 25.5834 - loss_accuracy: 0.0072 - val_loss: 64.5433 - val_loss_accuracy: 0.0023\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 26.2805 - loss_accuracy: 0.0063 - val_loss: 66.9996 - val_loss_accuracy: 0.0018\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 24.7793 - loss_accuracy: 0.0073 - val_loss: 64.5886 - val_loss_accuracy: 0.0023\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 26.1605 - loss_accuracy: 0.0070 - val_loss: 70.4043 - val_loss_accuracy: 5.8036e-04\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 25.3312 - loss_accuracy: 0.0064 - val_loss: 66.2352 - val_loss_accuracy: 0.0030\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 24.5412 - loss_accuracy: 0.0071 - val_loss: 70.0674 - val_loss_accuracy: 0.0021\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 23.9537 - loss_accuracy: 0.0069 - val_loss: 66.9078 - val_loss_accuracy: 0.0014\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 24.9550 - loss_accuracy: 0.0061 - val_loss: 63.8515 - val_loss_accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 23.2537 - loss_accuracy: 0.0076 - val_loss: 65.4287 - val_loss_accuracy: 0.0029\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 24.1126 - loss_accuracy: 0.0078 - val_loss: 61.5582 - val_loss_accuracy: 0.0041\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 24.8890 - loss_accuracy: 0.0069 - val_loss: 61.1471 - val_loss_accuracy: 0.0032\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 22.8294 - loss_accuracy: 0.0078 - val_loss: 64.8191 - val_loss_accuracy: 0.0021\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 22.2316 - loss_accuracy: 0.0086 - val_loss: 65.0977 - val_loss_accuracy: 0.0023\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 25.7587 - loss_accuracy: 0.0065 - val_loss: 62.5975 - val_loss_accuracy: 0.0025\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 25.3453 - loss_accuracy: 0.0069 - val_loss: 62.7281 - val_loss_accuracy: 0.0025\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 24.3034 - loss_accuracy: 0.0072 - val_loss: 64.4051 - val_loss_accuracy: 0.0018\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 22.7301 - loss_accuracy: 0.0085 - val_loss: 63.9608 - val_loss_accuracy: 0.0023\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 21.3548 - loss_accuracy: 0.0095 - val_loss: 62.7698 - val_loss_accuracy: 0.0043\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 20.2188 - loss_accuracy: 0.0107 - val_loss: 60.2831 - val_loss_accuracy: 0.0016\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 19.2983 - loss_accuracy: 0.0109 - val_loss: 61.8912 - val_loss_accuracy: 0.0045\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 22.1251 - loss_accuracy: 0.0086 - val_loss: 65.5226 - val_loss_accuracy: 0.0020\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 22.1841 - loss_accuracy: 0.0083 - val_loss: 65.6779 - val_loss_accuracy: 0.0018\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 22.0455 - loss_accuracy: 0.0087 - val_loss: 63.9255 - val_loss_accuracy: 0.0016\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 19.8033 - loss_accuracy: 0.0102 - val_loss: 63.6806 - val_loss_accuracy: 0.0025\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 18.1734 - loss_accuracy: 0.0124 - val_loss: 67.7892 - val_loss_accuracy: 0.0018\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 21.4876 - loss_accuracy: 0.0084 - val_loss: 62.2227 - val_loss_accuracy: 0.0045\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 20.0986 - loss_accuracy: 0.0099 - val_loss: 65.6112 - val_loss_accuracy: 0.0023\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 18.5620 - loss_accuracy: 0.0123 - val_loss: 63.6804 - val_loss_accuracy: 0.0011\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 18.1802 - loss_accuracy: 0.0117 - val_loss: 63.3525 - val_loss_accuracy: 0.0032\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 21.6200 - loss_accuracy: 0.0081 - val_loss: 64.0482 - val_loss_accuracy: 0.0029\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 18.0156 - loss_accuracy: 0.0108 - val_loss: 61.1684 - val_loss_accuracy: 0.0027\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 18.3547 - loss_accuracy: 0.0116 - val_loss: 61.8500 - val_loss_accuracy: 0.0032\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 17.6073 - loss_accuracy: 0.0135 - val_loss: 63.8991 - val_loss_accuracy: 0.0017\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 17.4070 - loss_accuracy: 0.0135 - val_loss: 60.6113 - val_loss_accuracy: 0.0032\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.8868 - loss_accuracy: 0.0156 - val_loss: 61.7398 - val_loss_accuracy: 0.0034\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 15.7119 - loss_accuracy: 0.0173 - val_loss: 60.8685 - val_loss_accuracy: 0.0029\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 17.1654 - loss_accuracy: 0.0136 - val_loss: 62.6048 - val_loss_accuracy: 0.0032\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 17.3952 - loss_accuracy: 0.0135 - val_loss: 66.4597 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 18.1481 - loss_accuracy: 0.0121 - val_loss: 61.5083 - val_loss_accuracy: 0.0047\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.3720 - loss_accuracy: 0.0129 - val_loss: 60.4353 - val_loss_accuracy: 0.0043\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 17.3166 - loss_accuracy: 0.0130 - val_loss: 60.8789 - val_loss_accuracy: 0.0039\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 17.8334 - loss_accuracy: 0.0114 - val_loss: 59.7264 - val_loss_accuracy: 0.0063\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 18.7435 - loss_accuracy: 0.0117 - val_loss: 64.4288 - val_loss_accuracy: 0.0020\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.0172 - loss_accuracy: 0.0159 - val_loss: 61.7503 - val_loss_accuracy: 0.0050\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.5425 - loss_accuracy: 0.0136 - val_loss: 60.1276 - val_loss_accuracy: 0.0033\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.3185 - loss_accuracy: 0.0150 - val_loss: 61.3085 - val_loss_accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.3620 - loss_accuracy: 0.0142 - val_loss: 60.9063 - val_loss_accuracy: 0.0025\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.7258 - loss_accuracy: 0.0145 - val_loss: 61.3852 - val_loss_accuracy: 0.0034\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 15.0329 - loss_accuracy: 0.0176 - val_loss: 65.3726 - val_loss_accuracy: 0.0027\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.9722 - loss_accuracy: 0.0150 - val_loss: 61.1020 - val_loss_accuracy: 0.0031\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 15.7049 - loss_accuracy: 0.0149 - val_loss: 62.3373 - val_loss_accuracy: 0.0037\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.1479 - loss_accuracy: 0.0150 - val_loss: 62.5532 - val_loss_accuracy: 0.0021\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 14.6862 - loss_accuracy: 0.0179 - val_loss: 62.7380 - val_loss_accuracy: 0.0023\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 14.9147 - loss_accuracy: 0.0186 - val_loss: 63.4378 - val_loss_accuracy: 0.0023\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 13.4905 - loss_accuracy: 0.0228 - val_loss: 64.1283 - val_loss_accuracy: 0.0025\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 16.1090 - loss_accuracy: 0.0154 - val_loss: 61.8209 - val_loss_accuracy: 0.0020\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 13s 8ms/step - loss: 14.6867 - loss_accuracy: 0.0193 - val_loss: 61.0833 - val_loss_accuracy: 0.0038\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history = model.fit(train_X, train_Y, epochs=100,batch_size=64, validation_data = (val_list,val_label),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "with tf.device('/device:GPU:0'):\n",
    "    loss,evaluation_metric_loss = model.evaluate(test_list, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.74504180908203\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    pred = model.predict(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46.973225  84.177     83.005135 125.44217  169.66284  106.70624\n",
      "  129.22632   55.823048  92.20912  169.3768   140.30469  174.49522\n",
      "  140.66011  152.4027  ]\n",
      " [208.1998   161.95995  113.92505  112.64477  163.4359   196.07788\n",
      "   84.65019   82.85775   50.968502  53.577644  75.67746   90.58651\n",
      "   44.530647  17.0624  ]]\n",
      "[[ 50.20740877  83.82652876  85.02721161 130.65316017 172.67706016\n",
      "  105.43882018 130.65316017  61.01355448  95.83335733 170.27569445\n",
      "  142.65998874 173.87774302 141.45930588 151.06476874]\n",
      " [206.30842279 161.39537968 115.06402995 115.53679882 160.92261081\n",
      "  191.65258767  83.38851533  84.80682196  53.60407622  53.60407622\n",
      "   74.87867558  87.64343521  47.45808084  19.56471723]]\n"
     ]
    }
   ],
   "source": [
    "print(pred[0])\n",
    "print(train_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = K.sqrt(K.sum(K.square(pred[0] - test_label[0]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.array(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.reduce_sum(tf.to_int32(tf.greater(threshold, dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
