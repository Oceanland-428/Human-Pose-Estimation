{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from parse_lsp_data import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.models import Model,Input\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout,Reshape\n",
    "from keras.optimizers import SGD,Adam\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten,Activation, Average,GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11813043745794109285\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15785944679\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16161114909604377105\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15868438119\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12591459529331690316\n",
      "physical_device_desc: \"device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing and packing images and labels to lists.\n",
      "\n",
      "Start to process training dataset\n",
      "Done processing the training dataset\n",
      "Start to process validation dataset\n",
      "Done processing the validation dataset\n",
      "Start to process test dataset\n",
      "Done processing the test dataset\n"
     ]
    }
   ],
   "source": [
    "train_list, train_label, val_list, val_label, test_list, test_label = getLSPDataset(0.8, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X:  (1600, 227, 227, 3) val X:  (200, 227, 227, 3) test X:  (200, 227, 227, 3)\n",
      "train Y:  (1600, 2, 14) val Y:  (200, 2, 14) test Y:  (200, 2, 14)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_list\t# (N, 227, 227, 3)\n",
    "train_Y = train_label\t# (N, 2, 14)\n",
    "print(\"train X: \", train_list.shape, \"val X: \", val_list.shape, \"test X: \", test_list.shape)\n",
    "print(\"train Y: \", train_label.shape, \"val Y: \", val_label.shape, \"test Y: \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    stage1_model = applications.densenet.DenseNet121(input_shape=(227,227,3), \n",
    "                                                    include_top=False, weights='imagenet')\n",
    "    last = stage1_model.output\n",
    "    x = Flatten()(last)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(28, activation='relu')(x)\n",
    "    preds = Reshape((2,14))(x)\n",
    "    model = Model(stage1_model.input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_accuracy(y_true, y_pred):\n",
    "    diff = tf.square(y_true - y_pred)\n",
    "    loss = tf.reduce_sum(diff)\n",
    "    dist = tf.sqrt(tf.reduce_sum(diff, axis = 1))\t# (N, 2, 14) -> (N, 14)\n",
    "    accuracy = tf.reduce_sum(tf.to_int32(tf.greater(1.0, dist))) / 16/14\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss=euclidean_distance_loss, metrics=[loss_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('densenet121.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 200 samples\n",
      "Epoch 1/250\n",
      "1600/1600 [==============================] - 50s 31ms/step - loss: 173.8159 - loss_accuracy: 6.2500e-04 - val_loss: 3860.0699 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 2/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 152.9198 - loss_accuracy: 8.0357e-04 - val_loss: 124.6728 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 3/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 149.8443 - loss_accuracy: 0.0018 - val_loss: 452.7553 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 4/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 153.9985 - loss_accuracy: 0.0012 - val_loss: 2319.0758 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 5/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 149.1768 - loss_accuracy: 8.0357e-04 - val_loss: 329.9803 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 6/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 150.3404 - loss_accuracy: 8.0357e-04 - val_loss: 351.8922 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 7/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 145.7336 - loss_accuracy: 5.3571e-04 - val_loss: 443.3337 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 8/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 152.2986 - loss_accuracy: 9.8214e-04 - val_loss: 445.4770 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 9/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 144.4028 - loss_accuracy: 3.5714e-04 - val_loss: 408.4221 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 10/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 140.3774 - loss_accuracy: 0.0013 - val_loss: 367.0196 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 11/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 140.3168 - loss_accuracy: 0.0012 - val_loss: 276.5975 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 12/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 139.3536 - loss_accuracy: 8.0357e-04 - val_loss: 320.3084 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 13/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 138.6592 - loss_accuracy: 0.0014 - val_loss: 443.8926 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 14/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 136.0421 - loss_accuracy: 8.9286e-04 - val_loss: 445.4770 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 15/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 137.8036 - loss_accuracy: 0.0015 - val_loss: 427.2782 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 16/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 138.0765 - loss_accuracy: 0.0011 - val_loss: 431.5873 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 17/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 137.6226 - loss_accuracy: 0.0012 - val_loss: 358.2173 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 18/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.7602 - loss_accuracy: 0.0015 - val_loss: 310.1110 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 19/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.8739 - loss_accuracy: 0.0012 - val_loss: 315.3958 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 20/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.2102 - loss_accuracy: 5.3571e-04 - val_loss: 317.7245 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 21/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 133.0061 - loss_accuracy: 0.0012 - val_loss: 326.8393 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 22/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.5686 - loss_accuracy: 0.0012 - val_loss: 321.9775 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 23/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 135.9270 - loss_accuracy: 0.0014 - val_loss: 328.3079 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 24/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.2676 - loss_accuracy: 8.0357e-04 - val_loss: 299.8230 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 25/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.4270 - loss_accuracy: 0.0014 - val_loss: 317.0759 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 26/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.2385 - loss_accuracy: 9.8214e-04 - val_loss: 323.2763 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 27/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.3936 - loss_accuracy: 0.0014 - val_loss: 321.2494 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 28/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.6935 - loss_accuracy: 0.0015 - val_loss: 321.9197 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 29/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.9515 - loss_accuracy: 0.0011 - val_loss: 341.5459 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 30/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.2177 - loss_accuracy: 8.0357e-04 - val_loss: 361.3819 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 31/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.8309 - loss_accuracy: 0.0016 - val_loss: 317.0694 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 32/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.5541 - loss_accuracy: 0.0013 - val_loss: 319.8039 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 33/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.9030 - loss_accuracy: 0.0018 - val_loss: 324.4307 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 34/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.3739 - loss_accuracy: 9.8214e-04 - val_loss: 325.2536 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 35/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.2564 - loss_accuracy: 9.8214e-04 - val_loss: 311.8839 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 36/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.3653 - loss_accuracy: 0.0011 - val_loss: 315.6695 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 37/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.8753 - loss_accuracy: 0.0015 - val_loss: 305.2701 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 38/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.7769 - loss_accuracy: 9.8214e-04 - val_loss: 316.3701 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 39/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.4887 - loss_accuracy: 0.0019 - val_loss: 314.7054 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 40/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.9414 - loss_accuracy: 0.0015 - val_loss: 320.2488 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 41/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.9483 - loss_accuracy: 0.0017 - val_loss: 324.6042 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 42/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.7944 - loss_accuracy: 0.0012 - val_loss: 322.0007 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 43/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.8462 - loss_accuracy: 7.1429e-04 - val_loss: 311.2278 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 44/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.2251 - loss_accuracy: 0.0016 - val_loss: 321.4175 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 45/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.2687 - loss_accuracy: 0.0012 - val_loss: 301.2532 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 46/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.0271 - loss_accuracy: 0.0012 - val_loss: 308.1946 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 47/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.6227 - loss_accuracy: 9.8214e-04 - val_loss: 445.4770 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 48/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.0770 - loss_accuracy: 8.0357e-04 - val_loss: 444.1352 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 49/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.4912 - loss_accuracy: 0.0013 - val_loss: 414.7083 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 50/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.8976 - loss_accuracy: 0.0018 - val_loss: 328.4418 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 51/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.3113 - loss_accuracy: 0.0015 - val_loss: 311.9544 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 52/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.7362 - loss_accuracy: 8.9286e-04 - val_loss: 308.6358 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 53/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.6877 - loss_accuracy: 0.0012 - val_loss: 310.5994 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 54/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.8369 - loss_accuracy: 0.0017 - val_loss: 325.4409 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 55/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.3421 - loss_accuracy: 0.0017 - val_loss: 319.5717 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 56/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.2393 - loss_accuracy: 0.0016 - val_loss: 341.6209 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 57/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.9158 - loss_accuracy: 0.0018 - val_loss: 360.1957 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 58/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 151.3098 - loss_accuracy: 0.0013 - val_loss: 290.8843 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 59/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 154.6888 - loss_accuracy: 8.9286e-04 - val_loss: 278.8477 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 60/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 145.6638 - loss_accuracy: 6.2500e-04 - val_loss: 433.0644 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 61/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 139.0543 - loss_accuracy: 0.0013 - val_loss: 430.2689 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 62/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 137.2995 - loss_accuracy: 0.0015 - val_loss: 444.9138 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 63/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 136.3479 - loss_accuracy: 0.0013 - val_loss: 411.2919 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 64/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 136.7295 - loss_accuracy: 5.3571e-04 - val_loss: 318.9606 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 65/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 133.4823 - loss_accuracy: 0.0011 - val_loss: 329.6570 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 66/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 133.3937 - loss_accuracy: 7.1429e-04 - val_loss: 321.4952 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 67/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 133.9497 - loss_accuracy: 0.0015 - val_loss: 315.3597 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 68/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 135.3945 - loss_accuracy: 8.9286e-04 - val_loss: 301.6970 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 69/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 139.7839 - loss_accuracy: 9.8214e-04 - val_loss: 340.0976 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 70/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.7217 - loss_accuracy: 0.0015 - val_loss: 300.1358 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 71/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.9001 - loss_accuracy: 0.0013 - val_loss: 300.9193 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 72/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 133.7953 - loss_accuracy: 0.0012 - val_loss: 352.8354 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 73/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.5329 - loss_accuracy: 0.0015 - val_loss: 298.8361 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 74/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.5906 - loss_accuracy: 8.0357e-04 - val_loss: 306.7771 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 75/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.6650 - loss_accuracy: 6.2500e-04 - val_loss: 329.7719 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 76/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.5930 - loss_accuracy: 0.0014 - val_loss: 338.3384 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 77/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.6793 - loss_accuracy: 0.0012 - val_loss: 303.2793 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 78/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.5633 - loss_accuracy: 0.0012 - val_loss: 325.0858 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 79/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.2250 - loss_accuracy: 0.0021 - val_loss: 323.5360 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 80/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.7492 - loss_accuracy: 0.0014 - val_loss: 329.0205 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 81/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 133.7225 - loss_accuracy: 0.0015 - val_loss: 402.2927 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 82/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.2073 - loss_accuracy: 0.0012 - val_loss: 328.9611 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 83/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.9691 - loss_accuracy: 0.0019 - val_loss: 338.8477 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 84/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.8991 - loss_accuracy: 0.0017 - val_loss: 324.7717 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 85/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.6241 - loss_accuracy: 9.8214e-04 - val_loss: 307.0080 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 86/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.6282 - loss_accuracy: 9.8214e-04 - val_loss: 303.9062 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 87/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.9917 - loss_accuracy: 0.0012 - val_loss: 420.6640 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 88/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.8350 - loss_accuracy: 8.9286e-04 - val_loss: 338.7143 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 89/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.0959 - loss_accuracy: 0.0014 - val_loss: 352.9709 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 90/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.3073 - loss_accuracy: 0.0011 - val_loss: 329.8878 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 91/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.7916 - loss_accuracy: 0.0016 - val_loss: 314.2687 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 92/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.2747 - loss_accuracy: 8.0357e-04 - val_loss: 302.9858 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 93/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.2285 - loss_accuracy: 0.0011 - val_loss: 305.4631 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 94/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.5539 - loss_accuracy: 8.0357e-04 - val_loss: 292.3674 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 95/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.0035 - loss_accuracy: 0.0014 - val_loss: 310.8860 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 96/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.6255 - loss_accuracy: 7.1429e-04 - val_loss: 306.5656 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 97/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.3760 - loss_accuracy: 0.0014 - val_loss: 303.0766 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 98/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.9602 - loss_accuracy: 8.9286e-04 - val_loss: 299.5431 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 99/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.2424 - loss_accuracy: 0.0022 - val_loss: 301.3618 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 100/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.8094 - loss_accuracy: 0.0013 - val_loss: 298.4189 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 101/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.1506 - loss_accuracy: 0.0013 - val_loss: 300.7707 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 102/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.9991 - loss_accuracy: 0.0014 - val_loss: 293.6915 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 103/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.8102 - loss_accuracy: 0.0015 - val_loss: 312.4857 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 104/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.5520 - loss_accuracy: 8.9286e-04 - val_loss: 291.4785 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 105/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.3743 - loss_accuracy: 0.0013 - val_loss: 304.0467 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 106/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.2135 - loss_accuracy: 8.0357e-04 - val_loss: 295.1656 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 107/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.1003 - loss_accuracy: 0.0012 - val_loss: 296.0233 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 108/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.9678 - loss_accuracy: 0.0012 - val_loss: 301.1157 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 109/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.1148 - loss_accuracy: 0.0014 - val_loss: 304.0167 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 110/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.4633 - loss_accuracy: 0.0015 - val_loss: 311.6951 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 111/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.6311 - loss_accuracy: 0.0014 - val_loss: 322.3315 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 112/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.0114 - loss_accuracy: 0.0016 - val_loss: 299.0887 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 113/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.1395 - loss_accuracy: 0.0015 - val_loss: 301.7704 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 114/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.7699 - loss_accuracy: 0.0015 - val_loss: 301.5853 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 115/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.9078 - loss_accuracy: 0.0016 - val_loss: 306.2547 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 116/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.9533 - loss_accuracy: 0.0014 - val_loss: 289.1356 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 117/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.4423 - loss_accuracy: 0.0012 - val_loss: 291.1846 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 118/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 139.8043 - loss_accuracy: 0.0016 - val_loss: 323.5904 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 119/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.2072 - loss_accuracy: 0.0012 - val_loss: 285.9105 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 120/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.7776 - loss_accuracy: 0.0015 - val_loss: 300.8103 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 121/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.2067 - loss_accuracy: 0.0021 - val_loss: 297.6188 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 122/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.8217 - loss_accuracy: 0.0013 - val_loss: 291.5761 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 123/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 140.4715 - loss_accuracy: 0.0016 - val_loss: 314.9639 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 124/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 138.1147 - loss_accuracy: 0.0012 - val_loss: 309.5747 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 125/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 137.7076 - loss_accuracy: 0.0012 - val_loss: 302.0159 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 126/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 136.7870 - loss_accuracy: 0.0018 - val_loss: 297.3052 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 127/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 136.3596 - loss_accuracy: 7.1429e-04 - val_loss: 304.0907 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 128/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 145.3320 - loss_accuracy: 8.0357e-04 - val_loss: 347.4508 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 129/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 138.2444 - loss_accuracy: 7.1429e-04 - val_loss: 340.5007 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 130/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.8469 - loss_accuracy: 0.0017 - val_loss: 299.8749 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 131/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 134.6379 - loss_accuracy: 0.0017 - val_loss: 322.3444 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 132/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 133.8789 - loss_accuracy: 0.0014 - val_loss: 304.1434 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 133/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.0568 - loss_accuracy: 0.0015 - val_loss: 292.7632 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 134/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.6673 - loss_accuracy: 0.0019 - val_loss: 301.2899 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 135/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.7698 - loss_accuracy: 8.9286e-04 - val_loss: 306.9412 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 136/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.8798 - loss_accuracy: 0.0019 - val_loss: 300.2516 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 137/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 133.7210 - loss_accuracy: 0.0012 - val_loss: 390.3903 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 138/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 145.9375 - loss_accuracy: 0.0012 - val_loss: 406.7842 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 139/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.8168 - loss_accuracy: 0.0012 - val_loss: 372.5017 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 140/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.1986 - loss_accuracy: 0.0015 - val_loss: 289.8094 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 141/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 132.6304 - loss_accuracy: 0.0013 - val_loss: 335.9083 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 142/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.9814 - loss_accuracy: 0.0017 - val_loss: 320.7193 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 143/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.8504 - loss_accuracy: 0.0012 - val_loss: 300.2865 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 144/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.7159 - loss_accuracy: 8.9286e-04 - val_loss: 320.2422 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 145/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.9771 - loss_accuracy: 0.0016 - val_loss: 308.7686 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 146/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.1860 - loss_accuracy: 0.0012 - val_loss: 292.2997 - val_loss_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.7501 - loss_accuracy: 0.0017 - val_loss: 300.7142 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 148/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.4664 - loss_accuracy: 0.0012 - val_loss: 303.2743 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 149/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.8305 - loss_accuracy: 0.0012 - val_loss: 294.7759 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 150/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.9675 - loss_accuracy: 0.0014 - val_loss: 297.4034 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 151/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.3950 - loss_accuracy: 0.0011 - val_loss: 306.5498 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 152/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.4608 - loss_accuracy: 0.0017 - val_loss: 307.1624 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 153/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.3837 - loss_accuracy: 0.0022 - val_loss: 290.5909 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 154/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.5432 - loss_accuracy: 0.0012 - val_loss: 295.8562 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 155/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.0490 - loss_accuracy: 0.0017 - val_loss: 293.1191 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 156/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.3609 - loss_accuracy: 0.0017 - val_loss: 294.3792 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 157/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.9099 - loss_accuracy: 0.0017 - val_loss: 299.5981 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 158/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.6749 - loss_accuracy: 0.0011 - val_loss: 291.4411 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 159/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.2915 - loss_accuracy: 0.0012 - val_loss: 288.9778 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 160/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.4878 - loss_accuracy: 9.8214e-04 - val_loss: 296.1867 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 161/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.7184 - loss_accuracy: 7.1429e-04 - val_loss: 317.1510 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 162/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.8750 - loss_accuracy: 0.0017 - val_loss: 307.9923 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 163/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.7893 - loss_accuracy: 0.0014 - val_loss: 292.5299 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 164/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.1045 - loss_accuracy: 0.0015 - val_loss: 291.3483 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 165/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.6638 - loss_accuracy: 0.0012 - val_loss: 300.5599 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 166/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.1231 - loss_accuracy: 0.0015 - val_loss: 295.7790 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 167/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.5027 - loss_accuracy: 9.8214e-04 - val_loss: 285.3253 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 168/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.5653 - loss_accuracy: 0.0015 - val_loss: 289.5396 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 169/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.5344 - loss_accuracy: 0.0019 - val_loss: 289.9638 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 170/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.4547 - loss_accuracy: 0.0011 - val_loss: 283.6959 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 171/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.0437 - loss_accuracy: 0.0012 - val_loss: 289.3316 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 172/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.5437 - loss_accuracy: 9.8214e-04 - val_loss: 285.4323 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 173/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.0522 - loss_accuracy: 0.0016 - val_loss: 280.7475 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 174/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.6433 - loss_accuracy: 0.0018 - val_loss: 280.4676 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 175/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.8277 - loss_accuracy: 0.0013 - val_loss: 284.3010 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 176/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.2946 - loss_accuracy: 0.0021 - val_loss: 276.8228 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 177/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.7723 - loss_accuracy: 0.0015 - val_loss: 277.2649 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 178/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.3280 - loss_accuracy: 0.0014 - val_loss: 284.3786 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 179/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.8649 - loss_accuracy: 0.0014 - val_loss: 277.4442 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 180/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.9498 - loss_accuracy: 0.0024 - val_loss: 275.5578 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 181/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.3526 - loss_accuracy: 0.0015 - val_loss: 280.5778 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 182/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.3712 - loss_accuracy: 0.0015 - val_loss: 302.7434 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 183/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.9989 - loss_accuracy: 0.0011 - val_loss: 282.4454 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 184/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.5499 - loss_accuracy: 0.0012 - val_loss: 269.8298 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 185/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 138.8189 - loss_accuracy: 9.8214e-04 - val_loss: 312.4855 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 186/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 136.7835 - loss_accuracy: 0.0013 - val_loss: 288.7838 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 187/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 137.3923 - loss_accuracy: 7.1429e-04 - val_loss: 287.2945 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 188/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.7515 - loss_accuracy: 0.0016 - val_loss: 282.6729 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 189/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 131.2049 - loss_accuracy: 0.0015 - val_loss: 282.7976 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 190/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.1898 - loss_accuracy: 0.0016 - val_loss: 289.3178 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 191/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.2444 - loss_accuracy: 0.0014 - val_loss: 286.3640 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 192/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.9902 - loss_accuracy: 0.0014 - val_loss: 290.6325 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 193/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.0322 - loss_accuracy: 0.0013 - val_loss: 283.3111 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 194/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.1067 - loss_accuracy: 0.0016 - val_loss: 286.9625 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 195/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.9972 - loss_accuracy: 0.0016 - val_loss: 279.2671 - val_loss_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.0121 - loss_accuracy: 0.0015 - val_loss: 283.8058 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 197/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.1292 - loss_accuracy: 0.0017 - val_loss: 291.6923 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 198/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.7340 - loss_accuracy: 0.0014 - val_loss: 274.4857 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 199/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 130.4865 - loss_accuracy: 0.0012 - val_loss: 283.3124 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 200/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.6265 - loss_accuracy: 0.0011 - val_loss: 276.2734 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 201/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.5347 - loss_accuracy: 0.0012 - val_loss: 284.3443 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 202/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.1736 - loss_accuracy: 0.0017 - val_loss: 279.0137 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 203/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.7923 - loss_accuracy: 0.0017 - val_loss: 279.5172 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 204/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.0689 - loss_accuracy: 0.0013 - val_loss: 283.0376 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 205/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.0257 - loss_accuracy: 0.0012 - val_loss: 274.2024 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 206/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.4720 - loss_accuracy: 0.0012 - val_loss: 278.7348 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 207/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.2605 - loss_accuracy: 0.0019 - val_loss: 267.3766 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 208/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.7091 - loss_accuracy: 0.0017 - val_loss: 275.6678 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 209/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.2139 - loss_accuracy: 0.0019 - val_loss: 271.8680 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 210/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.2619 - loss_accuracy: 0.0021 - val_loss: 269.3740 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 211/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.9192 - loss_accuracy: 0.0015 - val_loss: 282.7085 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 212/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.0077 - loss_accuracy: 0.0012 - val_loss: 279.6609 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 213/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.1678 - loss_accuracy: 0.0018 - val_loss: 264.6946 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 214/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.6368 - loss_accuracy: 0.0024 - val_loss: 262.0882 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 215/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.7713 - loss_accuracy: 0.0016 - val_loss: 301.0226 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 216/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.2744 - loss_accuracy: 0.0017 - val_loss: 279.1098 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 217/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.3629 - loss_accuracy: 0.0018 - val_loss: 276.0069 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 218/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.7980 - loss_accuracy: 0.0014 - val_loss: 271.3429 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 219/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 127.0760 - loss_accuracy: 0.0021 - val_loss: 269.7232 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 220/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 129.5862 - loss_accuracy: 0.0012 - val_loss: 269.2657 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 221/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.8025 - loss_accuracy: 0.0013 - val_loss: 264.8685 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 222/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.8606 - loss_accuracy: 0.0026 - val_loss: 268.5855 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 223/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.3376 - loss_accuracy: 0.0020 - val_loss: 265.2266 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 224/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 122.5157 - loss_accuracy: 0.0019 - val_loss: 256.1048 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 225/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.1031 - loss_accuracy: 0.0013 - val_loss: 262.5463 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 226/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 122.6807 - loss_accuracy: 0.0019 - val_loss: 259.8241 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 227/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 122.1909 - loss_accuracy: 0.0024 - val_loss: 260.4237 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 228/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 122.3965 - loss_accuracy: 0.0022 - val_loss: 256.5542 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 229/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.0812 - loss_accuracy: 0.0018 - val_loss: 253.3175 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 230/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.6103 - loss_accuracy: 0.0022 - val_loss: 255.4281 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 231/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.5478 - loss_accuracy: 9.8214e-04 - val_loss: 257.7426 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 232/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 122.0035 - loss_accuracy: 0.0022 - val_loss: 253.5749 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 233/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.5240 - loss_accuracy: 0.0021 - val_loss: 246.5312 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 234/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.5394 - loss_accuracy: 0.0017 - val_loss: 245.8102 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 235/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.5947 - loss_accuracy: 0.0019 - val_loss: 248.8997 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 236/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 122.8639 - loss_accuracy: 0.0019 - val_loss: 253.8454 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 237/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 122.9270 - loss_accuracy: 0.0020 - val_loss: 240.7593 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 238/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.0074 - loss_accuracy: 0.0016 - val_loss: 240.2135 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 239/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.5427 - loss_accuracy: 0.0013 - val_loss: 231.9341 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 240/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.3457 - loss_accuracy: 0.0015 - val_loss: 237.2206 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 241/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.3716 - loss_accuracy: 0.0020 - val_loss: 237.6436 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 242/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 120.8417 - loss_accuracy: 0.0021 - val_loss: 237.2581 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 243/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 123.5702 - loss_accuracy: 0.0012 - val_loss: 236.2685 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 244/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 128.4906 - loss_accuracy: 0.0013 - val_loss: 243.2178 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 245/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 19s 12ms/step - loss: 126.6621 - loss_accuracy: 0.0021 - val_loss: 238.3051 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 246/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 124.3227 - loss_accuracy: 0.0019 - val_loss: 232.6647 - val_loss_accuracy: 7.1429e-04\n",
      "Epoch 247/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 122.9109 - loss_accuracy: 0.0012 - val_loss: 239.7292 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 248/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 121.9705 - loss_accuracy: 0.0016 - val_loss: 238.2647 - val_loss_accuracy: 0.0000e+00\n",
      "Epoch 249/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 120.8739 - loss_accuracy: 0.0021 - val_loss: 228.9356 - val_loss_accuracy: 0.0014\n",
      "Epoch 250/250\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 125.6000 - loss_accuracy: 9.8214e-04 - val_loss: 240.7791 - val_loss_accuracy: 7.1429e-04\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    history = model.fit(train_X, train_Y, epochs=250,batch_size=32, validation_data = (val_list,val_label),callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    loss,evaluation_metric_loss = model.evaluate(test_list, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234.18685485839845\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    pred = model.predict(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49.167175 51.031292 51.449158 61.498085 65.01981  63.63407  49.603592\n",
      "  46.99698  50.50136  67.64647  71.24256  71.77015  59.253044 59.978153]\n",
      " [96.773155 77.621605 58.978848 59.5631   78.08154  96.364174 48.205986\n",
      "  43.848335 32.583057 32.47602  44.174232 49.316513 28.350435 16.537786]]\n",
      "[[ 50.20740877  83.82652876  85.02721161 130.65316017 172.67706016\n",
      "  105.43882018 130.65316017  61.01355448  95.83335733 170.27569445\n",
      "  142.65998874 173.87774302 141.45930588 151.06476874]\n",
      " [206.30842279 161.39537968 115.06402995 115.53679882 160.92261081\n",
      "  191.65258767  83.38851533  84.80682196  53.60407622  53.60407622\n",
      "   74.87867558  87.64343521  47.45808084  19.56471723]]\n"
     ]
    }
   ],
   "source": [
    "print(pred[0])\n",
    "print(train_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('denseNet_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
